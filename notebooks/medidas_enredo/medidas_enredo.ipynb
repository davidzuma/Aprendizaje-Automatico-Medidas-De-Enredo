{"cells":[{"cell_type":"markdown","metadata":{"id":"6mGK1hWTjeLh"},"source":["### Instalación de librerias e imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2ndQ6qMxkul","executionInfo":{"status":"ok","timestamp":1663152223974,"user_tz":-120,"elapsed":38840,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"outputId":"1ac5b738-69ba-4ac4-958a-8515884a0e88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting igraph\n","  Downloading igraph-0.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n","\u001b[K     |████████████████████████████████| 3.2 MB 8.1 MB/s \n","\u001b[?25hCollecting texttable>=1.6.2\n","  Downloading texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n","Installing collected packages: texttable, igraph\n","Successfully installed igraph-0.10.1 texttable-1.6.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cairocffi\n","  Downloading cairocffi-1.3.0.tar.gz (88 kB)\n","\u001b[K     |████████████████████████████████| 88 kB 3.1 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n","Building wheels for collected packages: cairocffi\n","  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cairocffi: filename=cairocffi-1.3.0-py3-none-any.whl size=89668 sha256=8cf8b136388a8a7d96d90a0111e744dc59096b42a394242b5d9b78500620a2da\n","  Stored in directory: /root/.cache/pip/wheels/4e/ca/e1/5c8a9692a27f639a07c949044bec943f26c81cd53d3805319f\n","Successfully built cairocffi\n","Installing collected packages: cairocffi\n","Successfully installed cairocffi-1.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-network\n","  Downloading scikit-network-0.27.0.tar.gz (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s \n","\u001b[?25h  Downloading scikit_network-0.26.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\n","\u001b[K     |████████████████████████████████| 8.1 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from scikit-network) (1.7.3)\n","Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.7/dist-packages (from scikit-network) (1.21.6)\n","Installing collected packages: scikit-network\n","Successfully installed scikit-network-0.26.0\n"]}],"source":["!pip install igraph\n","!pip install cairocffi\n","!pip install scikit-network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lfdAyE7is-lt"},"outputs":[],"source":["import pandas as pd\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras import backend as K\n","from tensorflow.python.framework.ops import disable_eager_execution\n","from sklearn.decomposition import PCA\n","import numpy as np\n","from numpy import vstack\n","from numpy import zeros\n","from numpy.random import rand\n","from numpy.linalg import norm\n","from sklearn.neighbors import kneighbors_graph\n","from sklearn.neighbors import radius_neighbors_graph\n","from sklearn.neighbors import radius_neighbors_graph\n","from statistics import stdev\n","import scipy.sparse\n","import igraph\n","import matplotlib.pyplot as plt\n","from tensorflow.python.framework.ops import disable_eager_execution\n","from IPython.display import SVG\n","from sknetwork.data import karate_club, painters, movie_actor\n","from sknetwork.topology import get_connected_components, get_largest_connected_component\n","from sknetwork.visualization import svg_graph, svg_bigraph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"im9AfM0aFaPD"},"outputs":[],"source":["# Necesario para ver entre las capas\n","disable_eager_execution()"]},{"cell_type":"markdown","metadata":{"id":"p53lLGrKBbh6"},"source":["### Función para sacar los outputs de la capas\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZqjrTCqBNIG"},"outputs":[],"source":["def get_layers_output(model, data):\n","\n","  inp = model.input                                           \n","  outputs = [layer.output for layer in model.layers]          \n","  functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs] \n","\n","  layer_outs = [func([x, 1.]) for func in functors]\n","  return layer_outs"]},{"cell_type":"markdown","metadata":{"id":"RtQq-3cnEzpU"},"source":["### Ejemplo para pintar grafos comentado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNYvV1DsvbwI"},"outputs":[],"source":["#labels = get_connected_components(matriz_grafo)\n","#image = svg_graph(matriz_grafo, labels=labels)\n","#new_adjacency, index = get_largest_connected_component(matriz_grafo, return_index=True)\n","#labels = get_connected_components(matriz_grafo)\n","#image = svg_graph(new_adjacency, labels=index)\n","#new_adjacency\n","#index\n","#SVG(image)\n","#new_adjacency\n","#len(index)"]},{"cell_type":"markdown","metadata":{"id":"Y5VArjLIB2gQ"},"source":["## Funciones para sacar los coeficientes de enredo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"of3bn0jQ2VBe"},"outputs":[],"source":["def get_grafo_knn(datos,ratio_min):\n","  k = 1\n","  matriz_grafo = kneighbors_graph(np.array(datos), k, mode='distance')\n","  matriz_grafo = matriz_grafo.todense()\n","  matriz_grafo = np.array(matriz_grafo)\n","\n","  for i in range(len(matriz_grafo)):\n","    for j in range(len(matriz_grafo)):\n","      matriz_grafo[j][i]=matriz_grafo[i][j]\n","  try:\n","    new_adjacency, index = get_largest_connected_component(matriz_grafo, return_index=True)\n","    ratio_connected = len(index)/len(datos)\n","  except:\n","    ratio_connected = 0\n","  if ratio_connected>ratio_min:\n","    matriz_grafo = new_adjacency.todense()\n","    g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","    print('Número de instancias:',len(index))\n","    print('número de vecinos:',k)\n","    return g\n","  g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","  while not g.is_connected():\n","    \n","    matriz_grafo = kneighbors_graph(datos, k, mode='distance')\n","    matriz_grafo = matriz_grafo.todense()\n","    matriz_grafo = np.array(matriz_grafo)\n","    \n","    for i in range(len(matriz_grafo)):\n","      for j in range(len(matriz_grafo)):\n","        matriz_grafo[j][i]=matriz_grafo[i][j]\n","    try:\n","      new_adjacency, index = get_largest_connected_component(matriz_grafo, return_index=True)\n","      ratio_connected = len(index)/len(datos)\n","    except:\n","      ratio_connected = 0\n","    if ratio_connected>ratio_min:\n","      matriz_grafo = new_adjacency.todense()\n","      g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","      print('Número de instancias:',len(index))\n","      print('número de vecinos:',k)\n","      return g\n","    g = igraph.Graph.Weighted_Adjacency(matriz_grafo,mode ='undirected')\n","    k +=1\n","  print('número de vecinos:', k)\n","  return g"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFZb4NohE5zX"},"outputs":[],"source":["# Radio para que sea conectado\n","def radio_minimo(datos, incremento=0.01):\n","  n_puntos = datos.shape[0]\n","  G_E = distancia_euclidea(datos)\n","  maximo_GE = np.amax(G_E)\n","  diagonal_grande = np.diag(np.zeros((n_puntos,)) + maximo_GE)\n","  radio = np.amax(np.amin(G_E + diagonal_grande, axis=0))\n","  radio = radio + incremento\n","  return radio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX1Xa7oq3FJS"},"outputs":[],"source":["def get_grafo_rnn(datos,ratio_min):\n","  radius = 0.01\n","  n_puntos = datos.shape[0]\n","  matriz_grafo = radius_neighbors_graph(np.array(datos), radius, mode='distance')\n","  matriz_grafo = matriz_grafo.todense()\n","  g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","\n","  while not g.is_connected():\n","    n_puntos = datos.shape[0]\n","    matriz_grafo = radius_neighbors_graph(datos, radius, mode='distance')\n","    try:\n","      new_adjacency, index = get_largest_connected_component(matriz_grafo, return_index=True)\n","      ratio_connected = len(index)/len(datos)\n","    except:\n","      ratio_connected = 0\n","    if ratio_connected>ratio_min:\n","      matriz_grafo = new_adjacency.todense()\n","      g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","      print('Número de instancias:',len(index))\n","      print('radio:',radius)\n","      return g\n","    matriz_grafo = matriz_grafo.todense()\n","    g = igraph.Graph.Weighted_Adjacency(matriz_grafo, mode='undirected')\n","\n","    radius += 0.01  \n","  print('radio:',radius)\n","  return g"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftf2xTr_tTTP"},"outputs":[],"source":["def distancia_euclidea(datos, dim):\n","  #n_puntos = datos.shape[0]\n","  G_E = zeros((dim, dim))\n","  for i in range(dim):\n","    for j in range(dim):\n","      G_E[i, j] = norm(datos[i]-datos[j])\n","  return G_E"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hb18swgFt8Fq"},"outputs":[],"source":["def distancia_geodesica(datos,ratio_min,tipo):\n","  #radio_min = radio_minimo(datos)\n","\n","  grafo = get_grafo_rnn(datos,ratio_min) if tipo == 'r' else get_grafo_knn(datos,ratio_min)\n","  caminos = grafo.distances(weights='weight')\n","  caminos = np.asarray(caminos)\n","  return caminos, len(caminos)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fi10duCK_sFA"},"outputs":[],"source":["def vector_triu(matriz):\n","  n = matriz.shape[0]\n","  i, j = np.triu_indices(n-1)\n","  return matriz[i, j+1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqCROIWi_L2t"},"outputs":[],"source":["def coef_entangle(datos,ratio_min,tipo):\n","# g es el grafo correspondiente a datos\n","  G_M, dim = distancia_geodesica(datos,ratio_min,tipo)\n","  G_E = distancia_euclidea(datos, dim)\n","  r_E = vector_triu(G_E)\n","  r_M = vector_triu(G_M)\n","  c = np.mean(1-np.multiply(r_M - np.mean(r_M), r_E - np.mean(r_E)) / (stdev(r_E)*stdev(r_M)))\n","  d = np.mean(np.divide(np.abs(r_M - r_E), r_E))  \n","  return c, d"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gw9mkF9eFEGM"},"outputs":[],"source":["def remove_outliers(layer):\n","  mu = [np.mean(l) for l in layer.transpose()]\n","  dev =  [np.std(l) for l in layer.transpose()]\n","  layer = np.array([point for point in layer if norm(point-mu)<norm(dev)])\n","  print('número de datos:',len(layer))\n","  return layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-0ccI68LhoM"},"outputs":[],"source":["def do_report(x,layer_outputs,mask_0,mask_1,max_capas,ratio_min,tipo):\n","  input_0 = np.array(x.iloc[mask_0])\n","  input_1 = np.array(x.iloc[mask_1])\n","  print(f'------------ Input ------------')\n","  print('Variedad_0: c, d',coef_entangle(input_0,ratio_min,tipo))\n","  print('Variedad_1: c, d',coef_entangle(input_1,ratio_min,tipo))\n","\n","  for id, layer_out in enumerate(layer_outputs[:max_capas]):\n","    l = list(map(list, zip(*layer_out)))\n","    layer_data = np.array([row[0] for row in l])\n","    layer_out_0 = layer_data[mask_0]\n","    layer_out_1 = layer_data[mask_1]\n","    print(f'------------CAPA {id+1}------------')\n","    print('Variedad_0: c, d:',coef_entangle(layer_out_0,ratio_min,tipo))\n","    print('Variedad_1: c, d',coef_entangle(layer_out_1,ratio_min,tipo))\n","  return None\n"]},{"cell_type":"code","source":["def do_report_table(x,layer_outputs,mask_0,mask_1,max_capas=4,ratio_min=0.6,tipo ='r'):\n","  input_0 = np.array(x.iloc[mask_0])\n","  input_1 = np.array(x.iloc[mask_1])\n","  df = pd.DataFrame(\n","   columns =['c - Clase 8', 'd-Clase 8', 'c-Clase 1', 'd-Clase 1']\n",")\n","  \n","  c_0,d_0 = coef_entangle(input_0,ratio_min,tipo)\n","  c_1,d_1 = coef_entangle(input_1,ratio_min,tipo)\n","\n","  df.loc['Entrada'] = [c_0,d_0,c_1,d_1]\n","\n","\n","  for id, layer_out in enumerate(layer_outputs[:max_capas]):\n","    print(f'------------CAPA {id+1}------------')\n","    l = list(map(list, zip(*layer_out)))\n","    layer_data = np.array([row[0] for row in l])\n","    layer_out_1 = layer_data[mask_1]\n","    layer_out_0 = layer_data[mask_0]\n","    c_0,d_0 = coef_entangle(layer_out_0,ratio_min,tipo)\n","    c_1,d_1 = coef_entangle(layer_out_1,ratio_min,tipo)\n","    df.loc[f'Capa {id+1}'] = [c_0,d_0,c_1,d_1]\n","  return df"],"metadata":{"id":"xQ8F2CC5h2w0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(\n","    {\n","    'Medida de enredo' : ['c','d','c','d']}\n",")\n","df = df.transpose()\n","#df.columns= df.loc['Clase']\n","df.columns =['Clase 1', 'Clase 1', 'Clase 0', 'Clase 0']\n"],"metadata":{"id":"r1Q4nThnc92f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pikEY2k6Iozz"},"source":["# EJEMPLOS"]},{"cell_type":"markdown","metadata":{"id":"TmrDDi9RHwW6"},"source":["## DATASET ESPIRAL"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1663152230253,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"JXbJoYditHfc","outputId":"f5387d2c-aa4f-49bd-b644-bd50e5c07d3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["def spiral_xy(i, spiral_num, freq):\n","    \"\"\"\n","    Create the data for a spiral.\n","    \"\"\"\n","    φ = math.pi*i/(freq*16)  \n","    r = 6.5 * ((freq*104 - i)/(freq*104))\n","    x = (r * math.cos(φ) * spiral_num)/13 + 0.5\n","    y = (r * math.sin(φ) * spiral_num)/13 + 0.5\n","    return (x, y)\n","\n","def spiral(spiral_num):\n","    return [spiral_xy(i,spiral_num,1) for i in range(80)]\n","\n","\n","a_x = list(zip(*spiral(1)))[0]\n","a_y = list(zip(*spiral(1)))[1]\n","\n","b_x = list(zip(*spiral(-1)))[0]\n","b_y = list(zip(*spiral(-1)))[1]\n","\n","plt.figure(figsize=(8, 8))\n","\n","plt.scatter(a_x,a_y, label = 'clase 1')\n","plt.scatter(b_x,b_y,  label = 'clase 0')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lt3VkGhStwjp"},"outputs":[],"source":["data_class_1 = [[x,y,1] for x,y in spiral(1)]\n","data_class_0 = [[x,y,0] for x,y in spiral(-1)]\n","data = data_class_1+data_class_0\n","data_df =pd.DataFrame(data)\n","data_df = data_df.sample(frac=1).reset_index(drop=True)\n","x, y  = data_df.iloc[:,:-1],data_df.iloc[:,-1]\n"]},{"cell_type":"markdown","metadata":{"id":"5nCn9cWXBINz"},"source":["### Entrenamiento de la red neuronal"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":14631,"status":"error","timestamp":1662919772087,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"Q44VFz_SA71a","outputId":"dd772421-b699-4407-f887-10f0b2500064"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 160 samples\n","Epoch 1/1250\n","160/160 [==============================] - 0s 2ms/sample - loss: 0.6929 - accuracy: 0.5437\n","Epoch 2/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.6926 - accuracy: 0.5000\n","Epoch 3/1250\n","160/160 [==============================] - 0s 110us/sample - loss: 0.6919 - accuracy: 0.5437\n","Epoch 4/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6917 - accuracy: 0.5500\n","Epoch 5/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.6910 - accuracy: 0.5562\n","Epoch 6/1250\n","160/160 [==============================] - 0s 107us/sample - loss: 0.6903 - accuracy: 0.5437\n","Epoch 7/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.6908 - accuracy: 0.5437\n","Epoch 8/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6887 - accuracy: 0.5562\n","Epoch 9/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.6905 - accuracy: 0.5312\n","Epoch 10/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.6891 - accuracy: 0.5312\n","Epoch 11/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6880 - accuracy: 0.5688\n","Epoch 12/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6892 - accuracy: 0.5375\n","Epoch 13/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.6874 - accuracy: 0.5688\n","Epoch 14/1250\n","160/160 [==============================] - 0s 135us/sample - loss: 0.6864 - accuracy: 0.5500\n","Epoch 15/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6860 - accuracy: 0.5562\n","Epoch 16/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.6854 - accuracy: 0.5688\n","Epoch 17/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.6854 - accuracy: 0.5625\n","Epoch 18/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6835 - accuracy: 0.5625\n","Epoch 19/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6845 - accuracy: 0.5625\n","Epoch 20/1250\n","160/160 [==============================] - 0s 151us/sample - loss: 0.6833 - accuracy: 0.5688\n","Epoch 21/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6837 - accuracy: 0.5813\n","Epoch 22/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6835 - accuracy: 0.5750\n","Epoch 23/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.6828 - accuracy: 0.5688\n","Epoch 24/1250\n","160/160 [==============================] - 0s 110us/sample - loss: 0.6835 - accuracy: 0.5750\n","Epoch 25/1250\n","160/160 [==============================] - 0s 100us/sample - loss: 0.6850 - accuracy: 0.5437\n","Epoch 26/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.6828 - accuracy: 0.5688\n","Epoch 27/1250\n","160/160 [==============================] - 0s 148us/sample - loss: 0.6858 - accuracy: 0.5500\n","Epoch 28/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.6833 - accuracy: 0.5750\n","Epoch 29/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6827 - accuracy: 0.5562\n","Epoch 30/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.6843 - accuracy: 0.5562\n","Epoch 31/1250\n","160/160 [==============================] - 0s 107us/sample - loss: 0.6838 - accuracy: 0.5625\n","Epoch 32/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6846 - accuracy: 0.5500\n","Epoch 33/1250\n","160/160 [==============================] - 0s 145us/sample - loss: 0.6816 - accuracy: 0.5750\n","Epoch 34/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6823 - accuracy: 0.5688\n","Epoch 35/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.6807 - accuracy: 0.5813\n","Epoch 36/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6817 - accuracy: 0.5750\n","Epoch 37/1250\n","160/160 [==============================] - 0s 111us/sample - loss: 0.6822 - accuracy: 0.5688\n","Epoch 38/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.6798 - accuracy: 0.5875\n","Epoch 39/1250\n","160/160 [==============================] - 0s 164us/sample - loss: 0.6812 - accuracy: 0.5625\n","Epoch 40/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.6802 - accuracy: 0.5625\n","Epoch 41/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.6793 - accuracy: 0.5813\n","Epoch 42/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.6785 - accuracy: 0.5750\n","Epoch 43/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.6800 - accuracy: 0.5750\n","Epoch 44/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6797 - accuracy: 0.5688\n","Epoch 45/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.6814 - accuracy: 0.5625\n","Epoch 46/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6803 - accuracy: 0.5813\n","Epoch 47/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6789 - accuracy: 0.5750\n","Epoch 48/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6783 - accuracy: 0.5750\n","Epoch 49/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6785 - accuracy: 0.5750\n","Epoch 50/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6779 - accuracy: 0.5688\n","Epoch 51/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6828 - accuracy: 0.5500\n","Epoch 52/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6794 - accuracy: 0.5813\n","Epoch 53/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6759 - accuracy: 0.5813\n","Epoch 54/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.6836 - accuracy: 0.5500\n","Epoch 55/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6789 - accuracy: 0.5938\n","Epoch 56/1250\n","160/160 [==============================] - 0s 104us/sample - loss: 0.6769 - accuracy: 0.5750\n","Epoch 57/1250\n","160/160 [==============================] - 0s 110us/sample - loss: 0.6767 - accuracy: 0.5813\n","Epoch 58/1250\n","160/160 [==============================] - 0s 177us/sample - loss: 0.6769 - accuracy: 0.5875\n","Epoch 59/1250\n","160/160 [==============================] - 0s 148us/sample - loss: 0.6761 - accuracy: 0.5813\n","Epoch 60/1250\n","160/160 [==============================] - 0s 160us/sample - loss: 0.6754 - accuracy: 0.5750\n","Epoch 61/1250\n","160/160 [==============================] - 0s 108us/sample - loss: 0.6758 - accuracy: 0.5750\n","Epoch 62/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6747 - accuracy: 0.5750\n","Epoch 63/1250\n","160/160 [==============================] - 0s 161us/sample - loss: 0.6745 - accuracy: 0.5875\n","Epoch 64/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.6770 - accuracy: 0.5875\n","Epoch 65/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6749 - accuracy: 0.5813\n","Epoch 66/1250\n","160/160 [==============================] - 0s 104us/sample - loss: 0.6748 - accuracy: 0.5875\n","Epoch 67/1250\n","160/160 [==============================] - 0s 103us/sample - loss: 0.6747 - accuracy: 0.5875\n","Epoch 68/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6739 - accuracy: 0.5813\n","Epoch 69/1250\n","160/160 [==============================] - 0s 102us/sample - loss: 0.6756 - accuracy: 0.5813\n","Epoch 70/1250\n","160/160 [==============================] - 0s 108us/sample - loss: 0.6757 - accuracy: 0.5688\n","Epoch 71/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.6761 - accuracy: 0.5500\n","Epoch 72/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6788 - accuracy: 0.5625\n","Epoch 73/1250\n","160/160 [==============================] - 0s 158us/sample - loss: 0.6710 - accuracy: 0.6000\n","Epoch 74/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.6749 - accuracy: 0.5750\n","Epoch 75/1250\n","160/160 [==============================] - 0s 102us/sample - loss: 0.6750 - accuracy: 0.5625\n","Epoch 76/1250\n","160/160 [==============================] - 0s 101us/sample - loss: 0.6728 - accuracy: 0.5813\n","Epoch 77/1250\n","160/160 [==============================] - 0s 115us/sample - loss: 0.6714 - accuracy: 0.5875\n","Epoch 78/1250\n","160/160 [==============================] - 0s 104us/sample - loss: 0.6731 - accuracy: 0.5938\n","Epoch 79/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6725 - accuracy: 0.5688\n","Epoch 80/1250\n","160/160 [==============================] - 0s 115us/sample - loss: 0.6727 - accuracy: 0.5813\n","Epoch 81/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.6705 - accuracy: 0.5813\n","Epoch 82/1250\n","160/160 [==============================] - 0s 111us/sample - loss: 0.6703 - accuracy: 0.5813\n","Epoch 83/1250\n","160/160 [==============================] - 0s 154us/sample - loss: 0.6706 - accuracy: 0.5938\n","Epoch 84/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.6700 - accuracy: 0.5875\n","Epoch 85/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.6728 - accuracy: 0.5813\n","Epoch 86/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6690 - accuracy: 0.5938\n","Epoch 87/1250\n","160/160 [==============================] - 0s 102us/sample - loss: 0.6732 - accuracy: 0.5688\n","Epoch 88/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6731 - accuracy: 0.5688\n","Epoch 89/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.6667 - accuracy: 0.5875\n","Epoch 90/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.6685 - accuracy: 0.5875\n","Epoch 91/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6683 - accuracy: 0.5813\n","Epoch 92/1250\n","160/160 [==============================] - 0s 140us/sample - loss: 0.6677 - accuracy: 0.6000\n","Epoch 93/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6676 - accuracy: 0.5938\n","Epoch 94/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.6694 - accuracy: 0.5813\n","Epoch 95/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.6679 - accuracy: 0.5875\n","Epoch 96/1250\n","160/160 [==============================] - 0s 140us/sample - loss: 0.6649 - accuracy: 0.5875\n","Epoch 97/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.6675 - accuracy: 0.5875\n","Epoch 98/1250\n","160/160 [==============================] - 0s 111us/sample - loss: 0.6668 - accuracy: 0.5938\n","Epoch 99/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6648 - accuracy: 0.5875\n","Epoch 100/1250\n","160/160 [==============================] - 0s 140us/sample - loss: 0.6623 - accuracy: 0.5813\n","Epoch 101/1250\n","160/160 [==============================] - 0s 152us/sample - loss: 0.6624 - accuracy: 0.5813\n","Epoch 102/1250\n","160/160 [==============================] - 0s 146us/sample - loss: 0.6618 - accuracy: 0.5750\n","Epoch 103/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.6652 - accuracy: 0.5750\n","Epoch 104/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6621 - accuracy: 0.5688\n","Epoch 105/1250\n","160/160 [==============================] - 0s 151us/sample - loss: 0.6596 - accuracy: 0.5813\n","Epoch 106/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6596 - accuracy: 0.5875\n","Epoch 107/1250\n","160/160 [==============================] - 0s 139us/sample - loss: 0.6571 - accuracy: 0.6000\n","Epoch 108/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6565 - accuracy: 0.5875\n","Epoch 109/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.6574 - accuracy: 0.5938\n","Epoch 110/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6622 - accuracy: 0.5813\n","Epoch 111/1250\n","160/160 [==============================] - 0s 106us/sample - loss: 0.6605 - accuracy: 0.6062\n","Epoch 112/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.6606 - accuracy: 0.5938\n","Epoch 113/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6503 - accuracy: 0.5875\n","Epoch 114/1250\n","160/160 [==============================] - 0s 111us/sample - loss: 0.6537 - accuracy: 0.6000\n","Epoch 115/1250\n","160/160 [==============================] - 0s 108us/sample - loss: 0.6529 - accuracy: 0.6000\n","Epoch 116/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6538 - accuracy: 0.6000\n","Epoch 117/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.6552 - accuracy: 0.5813\n","Epoch 118/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.6496 - accuracy: 0.6000\n","Epoch 119/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6501 - accuracy: 0.6125\n","Epoch 120/1250\n","160/160 [==============================] - 0s 151us/sample - loss: 0.6471 - accuracy: 0.5875\n","Epoch 121/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.6471 - accuracy: 0.6125\n","Epoch 122/1250\n","160/160 [==============================] - 0s 116us/sample - loss: 0.6465 - accuracy: 0.6125\n","Epoch 123/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6488 - accuracy: 0.6000\n","Epoch 124/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6569 - accuracy: 0.5625\n","Epoch 125/1250\n","160/160 [==============================] - 0s 145us/sample - loss: 0.6400 - accuracy: 0.6000\n","Epoch 126/1250\n","160/160 [==============================] - 0s 105us/sample - loss: 0.6436 - accuracy: 0.6250\n","Epoch 127/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6428 - accuracy: 0.5938\n","Epoch 128/1250\n","160/160 [==============================] - 0s 107us/sample - loss: 0.6423 - accuracy: 0.5938\n","Epoch 129/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.6384 - accuracy: 0.6250\n","Epoch 130/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6505 - accuracy: 0.5688\n","Epoch 131/1250\n","160/160 [==============================] - 0s 112us/sample - loss: 0.6326 - accuracy: 0.6313\n","Epoch 132/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.6336 - accuracy: 0.6250\n","Epoch 133/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.6352 - accuracy: 0.6062\n","Epoch 134/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.6371 - accuracy: 0.6062\n","Epoch 135/1250\n","160/160 [==============================] - 0s 107us/sample - loss: 0.6424 - accuracy: 0.5938\n","Epoch 136/1250\n","160/160 [==============================] - 0s 108us/sample - loss: 0.6388 - accuracy: 0.6062\n","Epoch 137/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.6353 - accuracy: 0.6062\n","Epoch 138/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.6355 - accuracy: 0.5938\n","Epoch 139/1250\n","160/160 [==============================] - 0s 371us/sample - loss: 0.6320 - accuracy: 0.6187\n","Epoch 140/1250\n","160/160 [==============================] - 0s 299us/sample - loss: 0.6304 - accuracy: 0.6125\n","Epoch 141/1250\n","160/160 [==============================] - 0s 253us/sample - loss: 0.6225 - accuracy: 0.6438\n","Epoch 142/1250\n","160/160 [==============================] - 0s 258us/sample - loss: 0.6292 - accuracy: 0.6062\n","Epoch 143/1250\n","160/160 [==============================] - 0s 158us/sample - loss: 0.6267 - accuracy: 0.6187\n","Epoch 144/1250\n","160/160 [==============================] - 0s 213us/sample - loss: 0.6242 - accuracy: 0.6187\n","Epoch 145/1250\n","160/160 [==============================] - 0s 204us/sample - loss: 0.6353 - accuracy: 0.6000\n","Epoch 146/1250\n","160/160 [==============================] - 0s 243us/sample - loss: 0.6505 - accuracy: 0.5688\n","Epoch 147/1250\n","160/160 [==============================] - 0s 202us/sample - loss: 0.6589 - accuracy: 0.5562\n","Epoch 148/1250\n","160/160 [==============================] - 0s 203us/sample - loss: 0.6509 - accuracy: 0.5625\n","Epoch 149/1250\n","160/160 [==============================] - 0s 215us/sample - loss: 0.6500 - accuracy: 0.5750\n","Epoch 150/1250\n","160/160 [==============================] - 0s 183us/sample - loss: 0.6442 - accuracy: 0.5750\n","Epoch 151/1250\n","160/160 [==============================] - 0s 217us/sample - loss: 0.6400 - accuracy: 0.5750\n","Epoch 152/1250\n","160/160 [==============================] - 0s 229us/sample - loss: 0.6389 - accuracy: 0.5813\n","Epoch 153/1250\n","160/160 [==============================] - 0s 231us/sample - loss: 0.6405 - accuracy: 0.5688\n","Epoch 154/1250\n","160/160 [==============================] - 0s 189us/sample - loss: 0.6379 - accuracy: 0.5750\n","Epoch 155/1250\n","160/160 [==============================] - 0s 290us/sample - loss: 0.6378 - accuracy: 0.5688\n","Epoch 156/1250\n","160/160 [==============================] - 0s 231us/sample - loss: 0.6357 - accuracy: 0.5813\n","Epoch 157/1250\n","160/160 [==============================] - 0s 182us/sample - loss: 0.6357 - accuracy: 0.5813\n","Epoch 158/1250\n","160/160 [==============================] - 0s 147us/sample - loss: 0.6355 - accuracy: 0.5625\n","Epoch 159/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.6309 - accuracy: 0.5813\n","Epoch 160/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.6316 - accuracy: 0.5750\n","Epoch 161/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.6331 - accuracy: 0.5688\n","Epoch 162/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.6413 - accuracy: 0.5688\n","Epoch 163/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6613 - accuracy: 0.5437\n","Epoch 164/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.6570 - accuracy: 0.5437\n","Epoch 165/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.6527 - accuracy: 0.5562\n","Epoch 166/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.6522 - accuracy: 0.5625\n","Epoch 167/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.6503 - accuracy: 0.5562\n","Epoch 168/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.6495 - accuracy: 0.5625\n","Epoch 169/1250\n","160/160 [==============================] - 0s 185us/sample - loss: 0.6459 - accuracy: 0.5625\n","Epoch 170/1250\n","160/160 [==============================] - 0s 142us/sample - loss: 0.6429 - accuracy: 0.5688\n","Epoch 171/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6376 - accuracy: 0.5750\n","Epoch 172/1250\n","160/160 [==============================] - 0s 115us/sample - loss: 0.6381 - accuracy: 0.5500\n","Epoch 173/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.6323 - accuracy: 0.5688\n","Epoch 174/1250\n","160/160 [==============================] - 0s 339us/sample - loss: 0.6354 - accuracy: 0.5688\n","Epoch 175/1250\n","160/160 [==============================] - 0s 169us/sample - loss: 0.6354 - accuracy: 0.5625\n","Epoch 176/1250\n","160/160 [==============================] - 0s 210us/sample - loss: 0.6375 - accuracy: 0.5750\n","Epoch 177/1250\n","160/160 [==============================] - 0s 240us/sample - loss: 0.6365 - accuracy: 0.5750\n","Epoch 178/1250\n","160/160 [==============================] - 0s 251us/sample - loss: 0.6284 - accuracy: 0.5688\n","Epoch 179/1250\n","160/160 [==============================] - 0s 292us/sample - loss: 0.6259 - accuracy: 0.5750\n","Epoch 180/1250\n","160/160 [==============================] - 0s 322us/sample - loss: 0.6263 - accuracy: 0.5750\n","Epoch 181/1250\n","160/160 [==============================] - 0s 301us/sample - loss: 0.6274 - accuracy: 0.5750\n","Epoch 182/1250\n","160/160 [==============================] - 0s 235us/sample - loss: 0.6245 - accuracy: 0.5938\n","Epoch 183/1250\n","160/160 [==============================] - 0s 253us/sample - loss: 0.6228 - accuracy: 0.6250\n","Epoch 184/1250\n","160/160 [==============================] - 0s 254us/sample - loss: 0.6245 - accuracy: 0.6250\n","Epoch 185/1250\n","160/160 [==============================] - 0s 237us/sample - loss: 0.6283 - accuracy: 0.5750\n","Epoch 186/1250\n","160/160 [==============================] - 0s 268us/sample - loss: 0.6241 - accuracy: 0.5688\n","Epoch 187/1250\n","160/160 [==============================] - 0s 200us/sample - loss: 0.6216 - accuracy: 0.6562\n","Epoch 188/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.6278 - accuracy: 0.6500\n","Epoch 189/1250\n","160/160 [==============================] - 0s 167us/sample - loss: 0.6211 - accuracy: 0.6375\n","Epoch 190/1250\n","160/160 [==============================] - 0s 285us/sample - loss: 0.6192 - accuracy: 0.6438\n","Epoch 191/1250\n","160/160 [==============================] - 0s 243us/sample - loss: 0.6190 - accuracy: 0.6375\n","Epoch 192/1250\n","160/160 [==============================] - 0s 183us/sample - loss: 0.6159 - accuracy: 0.6375\n","Epoch 193/1250\n","160/160 [==============================] - 0s 301us/sample - loss: 0.6159 - accuracy: 0.6438\n","Epoch 194/1250\n","160/160 [==============================] - 0s 282us/sample - loss: 0.6149 - accuracy: 0.6438\n","Epoch 195/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.6128 - accuracy: 0.6313\n","Epoch 196/1250\n","160/160 [==============================] - 0s 135us/sample - loss: 0.6119 - accuracy: 0.6375\n","Epoch 197/1250\n","160/160 [==============================] - 0s 140us/sample - loss: 0.6108 - accuracy: 0.6313\n","Epoch 198/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.6113 - accuracy: 0.6375\n","Epoch 199/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.6088 - accuracy: 0.6375\n","Epoch 200/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.6080 - accuracy: 0.6250\n","Epoch 201/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.6102 - accuracy: 0.6250\n","Epoch 202/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.6131 - accuracy: 0.6313\n","Epoch 203/1250\n","160/160 [==============================] - 0s 135us/sample - loss: 0.6032 - accuracy: 0.6500\n","Epoch 204/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.6044 - accuracy: 0.6438\n","Epoch 205/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.6020 - accuracy: 0.6562\n","Epoch 206/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.6010 - accuracy: 0.6500\n","Epoch 207/1250\n","160/160 [==============================] - 0s 147us/sample - loss: 0.5986 - accuracy: 0.6500\n","Epoch 208/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5966 - accuracy: 0.6562\n","Epoch 209/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5938 - accuracy: 0.6625\n","Epoch 210/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5943 - accuracy: 0.6375\n","Epoch 211/1250\n","160/160 [==============================] - 0s 144us/sample - loss: 0.5935 - accuracy: 0.6500\n","Epoch 212/1250\n","160/160 [==============================] - 0s 142us/sample - loss: 0.5915 - accuracy: 0.6500\n","Epoch 213/1250\n","160/160 [==============================] - 0s 408us/sample - loss: 0.5905 - accuracy: 0.6438\n","Epoch 214/1250\n","160/160 [==============================] - 0s 306us/sample - loss: 0.5910 - accuracy: 0.6562\n","Epoch 215/1250\n","160/160 [==============================] - 0s 328us/sample - loss: 0.5854 - accuracy: 0.6562\n","Epoch 216/1250\n","160/160 [==============================] - 0s 283us/sample - loss: 0.5979 - accuracy: 0.6438\n","Epoch 217/1250\n","160/160 [==============================] - 0s 274us/sample - loss: 0.5904 - accuracy: 0.6625\n","Epoch 218/1250\n","160/160 [==============================] - 0s 301us/sample - loss: 0.5964 - accuracy: 0.6250\n","Epoch 219/1250\n","160/160 [==============================] - 0s 312us/sample - loss: 0.5891 - accuracy: 0.6500\n","Epoch 220/1250\n","160/160 [==============================] - 0s 262us/sample - loss: 0.5937 - accuracy: 0.6562\n","Epoch 221/1250\n","160/160 [==============================] - 0s 417us/sample - loss: 0.5834 - accuracy: 0.6562\n","Epoch 222/1250\n","160/160 [==============================] - 0s 308us/sample - loss: 0.5855 - accuracy: 0.6375\n","Epoch 223/1250\n","160/160 [==============================] - 0s 274us/sample - loss: 0.5861 - accuracy: 0.6313\n","Epoch 224/1250\n","160/160 [==============================] - 0s 199us/sample - loss: 0.5927 - accuracy: 0.6438\n","Epoch 225/1250\n","160/160 [==============================] - 0s 189us/sample - loss: 0.5931 - accuracy: 0.6500\n","Epoch 226/1250\n","160/160 [==============================] - 0s 188us/sample - loss: 0.5916 - accuracy: 0.6500\n","Epoch 227/1250\n","160/160 [==============================] - 0s 226us/sample - loss: 0.5965 - accuracy: 0.6313\n","Epoch 228/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5904 - accuracy: 0.6562\n","Epoch 229/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5845 - accuracy: 0.6562\n","Epoch 230/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.5800 - accuracy: 0.6375\n","Epoch 231/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5814 - accuracy: 0.6375\n","Epoch 232/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5832 - accuracy: 0.6250\n","Epoch 233/1250\n","160/160 [==============================] - 0s 139us/sample - loss: 0.5892 - accuracy: 0.6562\n","Epoch 234/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5811 - accuracy: 0.6438\n","Epoch 235/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5770 - accuracy: 0.6562\n","Epoch 236/1250\n","160/160 [==============================] - 0s 115us/sample - loss: 0.5776 - accuracy: 0.6500\n","Epoch 237/1250\n","160/160 [==============================] - 0s 150us/sample - loss: 0.5746 - accuracy: 0.6562\n","Epoch 238/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5784 - accuracy: 0.6438\n","Epoch 239/1250\n","160/160 [==============================] - 0s 110us/sample - loss: 0.5765 - accuracy: 0.6313\n","Epoch 240/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5856 - accuracy: 0.6375\n","Epoch 241/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5696 - accuracy: 0.6562\n","Epoch 242/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5814 - accuracy: 0.6625\n","Epoch 243/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5692 - accuracy: 0.6562\n","Epoch 244/1250\n","160/160 [==============================] - 0s 109us/sample - loss: 0.5702 - accuracy: 0.6500\n","Epoch 245/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5696 - accuracy: 0.6562\n","Epoch 246/1250\n","160/160 [==============================] - 0s 156us/sample - loss: 0.5681 - accuracy: 0.6625\n","Epoch 247/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5698 - accuracy: 0.6625\n","Epoch 248/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5644 - accuracy: 0.6500\n","Epoch 249/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5671 - accuracy: 0.6375\n","Epoch 250/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.5647 - accuracy: 0.6438\n","Epoch 251/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5678 - accuracy: 0.6500\n","Epoch 252/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5654 - accuracy: 0.6625\n","Epoch 253/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5636 - accuracy: 0.6500\n","Epoch 254/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.5631 - accuracy: 0.6625\n","Epoch 255/1250\n","160/160 [==============================] - 0s 155us/sample - loss: 0.5596 - accuracy: 0.6500\n","Epoch 256/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5630 - accuracy: 0.6313\n","Epoch 257/1250\n","160/160 [==============================] - 0s 159us/sample - loss: 0.5615 - accuracy: 0.6375\n","Epoch 258/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5618 - accuracy: 0.6687\n","Epoch 259/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5694 - accuracy: 0.6438\n","Epoch 260/1250\n","160/160 [==============================] - 0s 111us/sample - loss: 0.5717 - accuracy: 0.6500\n","Epoch 261/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.5691 - accuracy: 0.6500\n","Epoch 262/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5689 - accuracy: 0.6562\n","Epoch 263/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5662 - accuracy: 0.6562\n","Epoch 264/1250\n","160/160 [==============================] - 0s 114us/sample - loss: 0.5662 - accuracy: 0.6375\n","Epoch 265/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5646 - accuracy: 0.6625\n","Epoch 266/1250\n","160/160 [==============================] - 0s 149us/sample - loss: 0.5625 - accuracy: 0.6687\n","Epoch 267/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5594 - accuracy: 0.6625\n","Epoch 268/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5576 - accuracy: 0.6687\n","Epoch 269/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5595 - accuracy: 0.6438\n","Epoch 270/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5589 - accuracy: 0.6500\n","Epoch 271/1250\n","160/160 [==============================] - 0s 155us/sample - loss: 0.5559 - accuracy: 0.6562\n","Epoch 272/1250\n","160/160 [==============================] - 0s 143us/sample - loss: 0.5531 - accuracy: 0.6625\n","Epoch 273/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.5537 - accuracy: 0.6438\n","Epoch 274/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5520 - accuracy: 0.6500\n","Epoch 275/1250\n","160/160 [==============================] - 0s 113us/sample - loss: 0.5521 - accuracy: 0.6500\n","Epoch 276/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5551 - accuracy: 0.6562\n","Epoch 277/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5562 - accuracy: 0.6562\n","Epoch 278/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.5499 - accuracy: 0.6562\n","Epoch 279/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5545 - accuracy: 0.6375\n","Epoch 280/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5512 - accuracy: 0.6438\n","Epoch 281/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5495 - accuracy: 0.6500\n","Epoch 282/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5484 - accuracy: 0.6625\n","Epoch 283/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5483 - accuracy: 0.6500\n","Epoch 284/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5536 - accuracy: 0.6687\n","Epoch 285/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5485 - accuracy: 0.6625\n","Epoch 286/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5529 - accuracy: 0.6438\n","Epoch 287/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5488 - accuracy: 0.6000\n","Epoch 288/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.5452 - accuracy: 0.6375\n","Epoch 289/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5538 - accuracy: 0.6562\n","Epoch 290/1250\n","160/160 [==============================] - 0s 117us/sample - loss: 0.5558 - accuracy: 0.6562\n","Epoch 291/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5472 - accuracy: 0.6562\n","Epoch 292/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5448 - accuracy: 0.6687\n","Epoch 293/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5418 - accuracy: 0.6500\n","Epoch 294/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5433 - accuracy: 0.6625\n","Epoch 295/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5418 - accuracy: 0.6687\n","Epoch 296/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5436 - accuracy: 0.6625\n","Epoch 297/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5458 - accuracy: 0.6500\n","Epoch 298/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5400 - accuracy: 0.6562\n","Epoch 299/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5424 - accuracy: 0.6375\n","Epoch 300/1250\n","160/160 [==============================] - 0s 147us/sample - loss: 0.5448 - accuracy: 0.6375\n","Epoch 301/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5406 - accuracy: 0.6500\n","Epoch 302/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5428 - accuracy: 0.6438\n","Epoch 303/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5446 - accuracy: 0.6500\n","Epoch 304/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5510 - accuracy: 0.6375\n","Epoch 305/1250\n","160/160 [==============================] - 0s 156us/sample - loss: 0.5496 - accuracy: 0.6438\n","Epoch 306/1250\n","160/160 [==============================] - 0s 161us/sample - loss: 0.5464 - accuracy: 0.6750\n","Epoch 307/1250\n","160/160 [==============================] - 0s 104us/sample - loss: 0.5459 - accuracy: 0.6625\n","Epoch 308/1250\n","160/160 [==============================] - 0s 164us/sample - loss: 0.5415 - accuracy: 0.6438\n","Epoch 309/1250\n","160/160 [==============================] - 0s 153us/sample - loss: 0.5387 - accuracy: 0.6562\n","Epoch 310/1250\n","160/160 [==============================] - 0s 165us/sample - loss: 0.5380 - accuracy: 0.6500\n","Epoch 311/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5360 - accuracy: 0.6562\n","Epoch 312/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.5356 - accuracy: 0.6500\n","Epoch 313/1250\n","160/160 [==============================] - 0s 143us/sample - loss: 0.5372 - accuracy: 0.6687\n","Epoch 314/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.5344 - accuracy: 0.6687\n","Epoch 315/1250\n","160/160 [==============================] - 0s 119us/sample - loss: 0.5363 - accuracy: 0.6625\n","Epoch 316/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5382 - accuracy: 0.6625\n","Epoch 317/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5327 - accuracy: 0.6562\n","Epoch 318/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5342 - accuracy: 0.6750\n","Epoch 319/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5323 - accuracy: 0.6625\n","Epoch 320/1250\n","160/160 [==============================] - 0s 115us/sample - loss: 0.5373 - accuracy: 0.6438\n","Epoch 321/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5339 - accuracy: 0.6625\n","Epoch 322/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5302 - accuracy: 0.6500\n","Epoch 323/1250\n","160/160 [==============================] - 0s 144us/sample - loss: 0.5311 - accuracy: 0.6250\n","Epoch 324/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5373 - accuracy: 0.6500\n","Epoch 325/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5305 - accuracy: 0.6500\n","Epoch 326/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5347 - accuracy: 0.6687\n","Epoch 327/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5432 - accuracy: 0.6500\n","Epoch 328/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.5414 - accuracy: 0.6625\n","Epoch 329/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5343 - accuracy: 0.6750\n","Epoch 330/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.5358 - accuracy: 0.6812\n","Epoch 331/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.5338 - accuracy: 0.6562\n","Epoch 332/1250\n","160/160 [==============================] - 0s 145us/sample - loss: 0.5296 - accuracy: 0.6500\n","Epoch 333/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5289 - accuracy: 0.6375\n","Epoch 334/1250\n","160/160 [==============================] - 0s 106us/sample - loss: 0.5323 - accuracy: 0.6500\n","Epoch 335/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.5315 - accuracy: 0.6625\n","Epoch 336/1250\n","160/160 [==============================] - 0s 142us/sample - loss: 0.5236 - accuracy: 0.6625\n","Epoch 337/1250\n","160/160 [==============================] - 0s 189us/sample - loss: 0.5238 - accuracy: 0.6500\n","Epoch 338/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5289 - accuracy: 0.6500\n","Epoch 339/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5318 - accuracy: 0.6687\n","Epoch 340/1250\n","160/160 [==============================] - 0s 172us/sample - loss: 0.5242 - accuracy: 0.6438\n","Epoch 341/1250\n","160/160 [==============================] - 0s 167us/sample - loss: 0.5206 - accuracy: 0.6438\n","Epoch 342/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5269 - accuracy: 0.6438\n","Epoch 343/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5572 - accuracy: 0.6250\n","Epoch 344/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5407 - accuracy: 0.6313\n","Epoch 345/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5358 - accuracy: 0.6500\n","Epoch 346/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5310 - accuracy: 0.6500\n","Epoch 347/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5537 - accuracy: 0.6562\n","Epoch 348/1250\n","160/160 [==============================] - 0s 142us/sample - loss: 0.5725 - accuracy: 0.6625\n","Epoch 349/1250\n","160/160 [==============================] - 0s 160us/sample - loss: 0.6022 - accuracy: 0.6438\n","Epoch 350/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.6486 - accuracy: 0.6062\n","Epoch 351/1250\n","160/160 [==============================] - 0s 157us/sample - loss: 0.6649 - accuracy: 0.5875\n","Epoch 352/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.6529 - accuracy: 0.5437\n","Epoch 353/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.6275 - accuracy: 0.5750\n","Epoch 354/1250\n","160/160 [==============================] - 0s 151us/sample - loss: 0.6235 - accuracy: 0.6000\n","Epoch 355/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.6274 - accuracy: 0.5813\n","Epoch 356/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.6662 - accuracy: 0.6125\n","Epoch 357/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.7085 - accuracy: 0.5500\n","Epoch 358/1250\n","160/160 [==============================] - 0s 332us/sample - loss: 0.6104 - accuracy: 0.6250\n","Epoch 359/1250\n","160/160 [==============================] - 0s 177us/sample - loss: 0.6311 - accuracy: 0.6125\n","Epoch 360/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.6928 - accuracy: 0.5625\n","Epoch 361/1250\n","160/160 [==============================] - 0s 143us/sample - loss: 0.6152 - accuracy: 0.6125\n","Epoch 362/1250\n","160/160 [==============================] - 0s 142us/sample - loss: 0.6545 - accuracy: 0.5813\n","Epoch 363/1250\n","160/160 [==============================] - 0s 138us/sample - loss: 0.6010 - accuracy: 0.5875\n","Epoch 364/1250\n","160/160 [==============================] - 0s 145us/sample - loss: 0.5951 - accuracy: 0.6375\n","Epoch 365/1250\n","160/160 [==============================] - 0s 143us/sample - loss: 0.5859 - accuracy: 0.6187\n","Epoch 366/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.5772 - accuracy: 0.6250\n","Epoch 367/1250\n","160/160 [==============================] - 0s 148us/sample - loss: 0.5722 - accuracy: 0.6438\n","Epoch 368/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5648 - accuracy: 0.6562\n","Epoch 369/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5576 - accuracy: 0.5938\n","Epoch 370/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5515 - accuracy: 0.6125\n","Epoch 371/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5540 - accuracy: 0.6062\n","Epoch 372/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5475 - accuracy: 0.6187\n","Epoch 373/1250\n","160/160 [==============================] - 0s 121us/sample - loss: 0.5502 - accuracy: 0.5938\n","Epoch 374/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5567 - accuracy: 0.6125\n","Epoch 375/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5520 - accuracy: 0.6375\n","Epoch 376/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5467 - accuracy: 0.6187\n","Epoch 377/1250\n","160/160 [==============================] - 0s 123us/sample - loss: 0.5488 - accuracy: 0.5875\n","Epoch 378/1250\n","160/160 [==============================] - 0s 135us/sample - loss: 0.5451 - accuracy: 0.6250\n","Epoch 379/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.5425 - accuracy: 0.6375\n","Epoch 380/1250\n","160/160 [==============================] - 0s 155us/sample - loss: 0.5396 - accuracy: 0.6438\n","Epoch 381/1250\n","160/160 [==============================] - 0s 131us/sample - loss: 0.5392 - accuracy: 0.6438\n","Epoch 382/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5402 - accuracy: 0.6375\n","Epoch 383/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5386 - accuracy: 0.6375\n","Epoch 384/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5427 - accuracy: 0.6625\n","Epoch 385/1250\n","160/160 [==============================] - 0s 150us/sample - loss: 0.5383 - accuracy: 0.6500\n","Epoch 386/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5466 - accuracy: 0.6500\n","Epoch 387/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5545 - accuracy: 0.6313\n","Epoch 388/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5635 - accuracy: 0.6125\n","Epoch 389/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5581 - accuracy: 0.6375\n","Epoch 390/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5523 - accuracy: 0.6438\n","Epoch 391/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5432 - accuracy: 0.6562\n","Epoch 392/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5423 - accuracy: 0.6313\n","Epoch 393/1250\n","160/160 [==============================] - 0s 126us/sample - loss: 0.5420 - accuracy: 0.6375\n","Epoch 394/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5371 - accuracy: 0.6500\n","Epoch 395/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5407 - accuracy: 0.6562\n","Epoch 396/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5360 - accuracy: 0.6500\n","Epoch 397/1250\n","160/160 [==============================] - 0s 148us/sample - loss: 0.5366 - accuracy: 0.6438\n","Epoch 398/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5390 - accuracy: 0.6125\n","Epoch 399/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5347 - accuracy: 0.6562\n","Epoch 400/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5338 - accuracy: 0.6500\n","Epoch 401/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.5307 - accuracy: 0.6500\n","Epoch 402/1250\n","160/160 [==============================] - 0s 129us/sample - loss: 0.5256 - accuracy: 0.6562\n","Epoch 403/1250\n","160/160 [==============================] - 0s 120us/sample - loss: 0.5470 - accuracy: 0.6562\n","Epoch 404/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5494 - accuracy: 0.6438\n","Epoch 405/1250\n","160/160 [==============================] - 0s 128us/sample - loss: 0.5461 - accuracy: 0.6562\n","Epoch 406/1250\n","160/160 [==============================] - 0s 165us/sample - loss: 0.5380 - accuracy: 0.6438\n","Epoch 407/1250\n","160/160 [==============================] - 0s 140us/sample - loss: 0.5351 - accuracy: 0.6562\n","Epoch 408/1250\n","160/160 [==============================] - 0s 163us/sample - loss: 0.5378 - accuracy: 0.6687\n","Epoch 409/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5316 - accuracy: 0.6687\n","Epoch 410/1250\n","160/160 [==============================] - 0s 127us/sample - loss: 0.5298 - accuracy: 0.6750\n","Epoch 411/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5227 - accuracy: 0.6562\n","Epoch 412/1250\n","160/160 [==============================] - 0s 132us/sample - loss: 0.5210 - accuracy: 0.6562\n","Epoch 413/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5206 - accuracy: 0.6562\n","Epoch 414/1250\n","160/160 [==============================] - 0s 125us/sample - loss: 0.5233 - accuracy: 0.6687\n","Epoch 415/1250\n","160/160 [==============================] - 0s 124us/sample - loss: 0.5230 - accuracy: 0.6625\n","Epoch 416/1250\n","160/160 [==============================] - 0s 130us/sample - loss: 0.5182 - accuracy: 0.6625\n","Epoch 417/1250\n","160/160 [==============================] - 0s 122us/sample - loss: 0.5212 - accuracy: 0.6562\n","Epoch 418/1250\n","160/160 [==============================] - 0s 118us/sample - loss: 0.5247 - accuracy: 0.6562\n","Epoch 419/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.5170 - accuracy: 0.6625\n","Epoch 420/1250\n","160/160 [==============================] - 0s 152us/sample - loss: 0.5247 - accuracy: 0.6562\n","Epoch 421/1250\n","160/160 [==============================] - 0s 174us/sample - loss: 0.5222 - accuracy: 0.6625\n","Epoch 422/1250\n","160/160 [==============================] - 0s 134us/sample - loss: 0.5209 - accuracy: 0.6687\n","Epoch 423/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.5279 - accuracy: 0.6625\n","Epoch 424/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.5317 - accuracy: 0.6687\n","Epoch 425/1250\n","160/160 [==============================] - 0s 144us/sample - loss: 0.5351 - accuracy: 0.6500\n","Epoch 426/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.5278 - accuracy: 0.6625\n","Epoch 427/1250\n","160/160 [==============================] - 0s 137us/sample - loss: 0.5425 - accuracy: 0.6750\n","Epoch 428/1250\n","160/160 [==============================] - 0s 150us/sample - loss: 0.5291 - accuracy: 0.6625\n","Epoch 429/1250\n","160/160 [==============================] - 0s 133us/sample - loss: 0.5196 - accuracy: 0.6375\n","Epoch 430/1250\n","160/160 [==============================] - 0s 149us/sample - loss: 0.5143 - accuracy: 0.6750\n","Epoch 431/1250\n","160/160 [==============================] - 0s 144us/sample - loss: 0.5095 - accuracy: 0.6687\n","Epoch 432/1250\n","160/160 [==============================] - 0s 149us/sample - loss: 0.5091 - accuracy: 0.6812\n","Epoch 433/1250\n","160/160 [==============================] - 0s 141us/sample - loss: 0.5088 - accuracy: 0.6750\n","Epoch 434/1250\n","160/160 [==============================] - 0s 144us/sample - loss: 0.5068 - accuracy: 0.6687\n","Epoch 435/1250\n","160/160 [==============================] - 0s 167us/sample - loss: 0.5064 - accuracy: 0.6875\n","Epoch 436/1250\n","160/160 [==============================] - 0s 146us/sample - loss: 0.5057 - accuracy: 0.6687\n","Epoch 437/1250\n","160/160 [==============================] - 0s 136us/sample - loss: 0.5054 - accuracy: 0.6375\n","Epoch 438/1250\n"," 30/160 [====>.........................] - ETA: 0s - loss: 0.4751 - accuracy: 0.7333"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-20e4e6672d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# hide the output because we have so many epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4275\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4276\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","# Fijamos la semilla para que no varie nuestro modelo de un entranamiento a otro\n","tf.random.set_seed(0)\n","optimizer = keras.optimizers.Adam(learning_rate=0.0015)\n","es = keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=1000, restore_best_weights=True)\n","model = keras.Sequential([\n","\n","    layers.Dense(units=20, activation='relu', input_shape=[2]),\n","    layers.Dense(units=20, activation='relu'),\n","    layers.Dense(units=15, activation='relu'),\n","    layers.Dense(units=10, activation='relu'),\n","    layers.Dense(units=10, activation='relu'),\n","    layers.Dense(units=10, activation='relu'),\n","    layers.Dense(units=5, activation='relu'),\n","    layers.Dense(units=5, activation='relu'),\n","\n","\n","    layers.Dense(units=1,activation = 'sigmoid'),\n","])\n","model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'],experimental_run_tf_function=False)\n","\n","history = model.fit(\n","    x,y ,\n","    batch_size=30,\n","    epochs=1250,\n","    callbacks = [es],\n","    verbose=1, # hide the output because we have so many epochs\n",")\n","\n","history_df = pd.DataFrame(history.history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7HWsUNTDVrW"},"outputs":[],"source":["accuracy = model.evaluate(x, y)[1]\n","layers_numbers = len(model.layers)\n","model_path = f'{layers_numbers}_layers_{accuracy:.2f}_accuracy.h5'\n","model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgB-Am-EDdm1"},"outputs":[],"source":["#model.save(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Slq9iQwOhwb"},"outputs":[],"source":["model.evaluate(x, y)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eM32CkTADhYM"},"outputs":[],"source":["model = keras.models.load_model('/content/drive/MyDrive/TFM Zumaquero (MAT)/9_layers_1.00_accuracy.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LweZAyOmKADp"},"outputs":[],"source":["layer_outputs = get_layers_output(model, x)\n","mask_spiral_1 = [i==1 for i in y]\n","mask_spiral_0 = [i==0 for i in y]"]},{"cell_type":"markdown","metadata":{"id":"18Y1p2kdGGf0"},"source":["### Reporte de las medidas de enredo aplicando el método del radio para el grafo de vecino próximo"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"elapsed":1000,"status":"error","timestamp":1663007037871,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"JPw6BEhgwivp","outputId":"ad172722-792c-42c7-f532-19505e036d32"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-5f2a003fc95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdo_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_spiral_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask_spiral_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: do_report() missing 1 required positional argument: 'tipo'"]}],"source":["do_report(x,layer_outputs,mask_spiral_0,mask_spiral_1,0.85,'r')\n"]},{"cell_type":"code","source":["print(do_report_table(x,layer_outputs,mask_spiral_0,mask_spiral_1,ratio_min = 0.85, max_capas=9,tipo = 'k').to_latex())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFZbIae4mt4k","executionInfo":{"status":"ok","timestamp":1663007939771,"user_tz":-120,"elapsed":2818,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"outputId":"38e97fbb-f66c-4ef5-f952-e6487a7f5d9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Número de instancias: 80\n","número de vecinos: 2\n","Número de instancias: 80\n","número de vecinos: 2\n","------------CAPA 1------------\n","Número de instancias: 80\n","número de vecinos: 2\n","Número de instancias: 80\n","número de vecinos: 2\n","------------CAPA 2------------\n","Número de instancias: 80\n","número de vecinos: 3\n","Número de instancias: 80\n","número de vecinos: 3\n","------------CAPA 3------------\n","Número de instancias: 71\n","número de vecinos: 3\n","Número de instancias: 80\n","número de vecinos: 3\n","------------CAPA 4------------\n","Número de instancias: 71\n","número de vecinos: 4\n","Número de instancias: 80\n","número de vecinos: 8\n","------------CAPA 5------------\n","Número de instancias: 69\n","número de vecinos: 7\n","Número de instancias: 80\n","número de vecinos: 12\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"output_type":"stream","name":"stdout","text":["------------CAPA 6------------\n","Número de instancias: 69\n","número de vecinos: 6\n","Número de instancias: 80\n","número de vecinos: 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"output_type":"stream","name":"stdout","text":["------------CAPA 7------------\n","Número de instancias: 69\n","número de vecinos: 5\n","Número de instancias: 80\n","número de vecinos: 7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"output_type":"stream","name":"stdout","text":["------------CAPA 8------------\n","Número de instancias: 69\n","número de vecinos: 4\n","Número de instancias: 79\n","número de vecinos: 8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"output_type":"stream","name":"stdout","text":["------------CAPA 9------------\n","Número de instancias: 80\n","número de vecinos: 9\n","Número de instancias: 79\n","número de vecinos: 8\n","\\begin{tabular}{lrrrr}\n","\\toprule\n","{} &  c - Clase 0 &  d-Clase 0 &  c-Clase 1 &  d-Clase 1 \\\\\n","\\midrule\n","Entrada &     0.774671 &   2.600329 &   0.747079 &   3.338851 \\\\\n","Capa 1  &     0.734755 &   2.675865 &   0.713226 &   3.471020 \\\\\n","Capa 2  &     0.618481 &   2.635013 &   0.665317 &   1.993438 \\\\\n","Capa 3  &     1.019668 &   1.840620 &   0.324711 &   1.823325 \\\\\n","Capa 4  &     0.974680 &   1.757115 &   0.404784 &   1.494007 \\\\\n","Capa 5  &     1.082427 &        inf &   0.195873 &   0.756577 \\\\\n","Capa 6  &     1.082466 &        inf &   0.145775 &   0.766150 \\\\\n","Capa 7  &     1.010973 &        inf &   0.025869 &   0.223875 \\\\\n","Capa 8  &     1.009014 &        inf &   0.022096 &   0.249882 \\\\\n","Capa 9  &     0.000322 &        NaN &   0.148876 &        inf \\\\\n","\\bottomrule\n","\\end{tabular}\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]}]},{"cell_type":"markdown","metadata":{"id":"NYEztlrIGLrw"},"source":["###Reporte de las medidas de enredo aplicando k vecimos más próximos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4956,"status":"ok","timestamp":1662664716571,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"_Ggw19New-ZN","outputId":"62729ef5-a1b0-4bf1-b4fd-b06909dcc480"},"outputs":[{"name":"stdout","output_type":"stream","text":["------------ Input ------------\n","Número de instancias: 80\n","número de vecinos: 2\n","Variedad_0: c, d (0.7746668737834463, 2.600304477706908)\n","Número de instancias: 80\n","número de vecinos: 2\n","Variedad_1: c, d (0.7746668737834463, 2.600304477706908)\n","------------CAPA 1------------\n","Número de instancias: 80\n","número de vecinos: 2\n","Variedad_0: c, d: (0.7449607703767789, 2.6500236194120648)\n","Número de instancias: 80\n","número de vecinos: 2\n","Variedad_1: c, d (0.7347487734324195, 2.675825513286094)\n","------------CAPA 2------------\n","Número de instancias: 78\n","número de vecinos: 2\n","Variedad_0: c, d: (0.8805227836661025, 4.743862905456993)\n","Número de instancias: 80\n","número de vecinos: 3\n","Variedad_1: c, d (0.6377476490434313, 2.2511114200159335)\n","------------CAPA 3------------\n","Número de instancias: 80\n","número de vecinos: 3\n","Variedad_0: c, d: (0.29304689125776173, 2.0091903001576252)\n","Número de instancias: 80\n","número de vecinos: 6\n","Variedad_1: c, d (0.09025735797582556, 0.7006310941471202)\n","------------CAPA 4------------\n","Número de instancias: 79\n","número de vecinos: 4\n","Variedad_0: c, d: (0.14742813046297468, 0.7529261725946427)\n","Número de instancias: 80\n","número de vecinos: 4\n","Variedad_1: c, d (0.03415191398532257, 0.56564913177764)\n","------------CAPA 5------------\n","Número de instancias: 80\n","número de vecinos: 9\n","Variedad_0: c, d: (0.32017999391795626, 1.3154755122929336)\n","Número de instancias: 74\n","número de vecinos: 4\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Variedad_1: c, d (0.9493429512319218, inf)\n","------------CAPA 6------------\n","Número de instancias: 80\n","número de vecinos: 6\n","Variedad_0: c, d: (0.1435279860588225, 0.6844298675029441)\n","Número de instancias: 80\n","número de vecinos: 6\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Variedad_1: c, d (0.0023055614521473337, inf)\n","------------CAPA 7------------\n","Número de instancias: 80\n","número de vecinos: 7\n","Variedad_0: c, d: (0.010705892263715239, 0.1938056889843944)\n","Número de instancias: 79\n","número de vecinos: 11\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Variedad_1: c, d (0.05760890301824602, inf)\n","------------CAPA 8------------\n","Número de instancias: 80\n","número de vecinos: 8\n","Variedad_0: c, d: (0.016553871537798047, 0.20422385714082222)\n","Número de instancias: 80\n","número de vecinos: 7\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Variedad_1: c, d (0.0003985693470025497, inf)\n","------------CAPA 9------------\n","Número de instancias: 76\n","número de vecinos: 5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"name":"stdout","output_type":"stream","text":["Variedad_0: c, d: (0.7759963206542018, inf)\n","Número de instancias: 80\n","número de vecinos: 6\n","Variedad_1: c, d (0.00032163311633701846, nan)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n","  \n"]}],"source":["do_report(x,layer_outputs,mask_spiral_1,mask_spiral_0,0.9,'k')"]},{"cell_type":"markdown","metadata":{"id":"XZlJ1pNlQF9m"},"source":["## DATASET DIGITOS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ow4HNXxXQuNd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663009655047,"user_tz":-120,"elapsed":885,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"outputId":"8de06da6-4072-4366-803b-6f449f4f1c39"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1797, 65)"]},"metadata":{},"execution_count":65}],"source":["from sklearn.datasets import load_digits\n","#from keras.datasets import mnist\n","import pandas as pd\n","\n","digits=load_digits(as_frame=True)\n","mnist.load_data()\n","X = digits.data\n","Y = digits.target\n","X['target'] = Y\n","\n","X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1663009299806,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"wPnq8XwSRLct","outputId":"264a0c3d-9e8a-4b97-cc81-4cc710e15b7c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"output_type":"execute_result","data":{"text/plain":["(356, 64)"]},"metadata":{},"execution_count":49}],"source":["\n","digits_mask = [i==8 or i==1 for i in Y]\n","digits_df = X.iloc[digits_mask]\n","digits_df['target'] = digits_df['target'].replace(8,0)\n","digits_df =digits_df.reset_index(drop =True)\n","x, y  =  digits_df.iloc[:,:-1],digits_df.iloc[:,-1]\n","x.shape\n","\n","#x.iloc[mask_digits_1]"]},{"cell_type":"markdown","metadata":{"id":"5p_67estJquQ"},"source":["### Entrenamos dataset de digitos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7433,"status":"ok","timestamp":1663011039693,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"uyqFmplEUw5r","outputId":"9150ea05-15a1-4af4-e9d6-a3be29f3aa70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 356 samples\n","Epoch 1/300\n","356/356 [==============================] - 0s 557us/sample - loss: 1.6305 - accuracy: 0.4888\n","Epoch 2/300\n","356/356 [==============================] - 0s 59us/sample - loss: 0.8806 - accuracy: 0.5281\n","Epoch 3/300\n","356/356 [==============================] - 0s 57us/sample - loss: 0.6145 - accuracy: 0.7303\n","Epoch 4/300\n","356/356 [==============================] - 0s 72us/sample - loss: 0.5816 - accuracy: 0.6826\n","Epoch 5/300\n","356/356 [==============================] - 0s 63us/sample - loss: 0.5514 - accuracy: 0.7022\n","Epoch 6/300\n","356/356 [==============================] - 0s 61us/sample - loss: 0.4990 - accuracy: 0.7640\n","Epoch 7/300\n","356/356 [==============================] - 0s 55us/sample - loss: 0.4559 - accuracy: 0.8287\n","Epoch 8/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.4152 - accuracy: 0.8567\n","Epoch 9/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.3742 - accuracy: 0.8596\n","Epoch 10/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.3427 - accuracy: 0.8736\n","Epoch 11/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.3125 - accuracy: 0.8876\n","Epoch 12/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.2828 - accuracy: 0.8989\n","Epoch 13/300\n","356/356 [==============================] - 0s 41us/sample - loss: 0.2532 - accuracy: 0.9045\n","Epoch 14/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.2321 - accuracy: 0.9073\n","Epoch 15/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.2132 - accuracy: 0.9354\n","Epoch 16/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.1943 - accuracy: 0.9438\n","Epoch 17/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.1794 - accuracy: 0.9466\n","Epoch 18/300\n","356/356 [==============================] - 0s 41us/sample - loss: 0.1671 - accuracy: 0.9466\n","Epoch 19/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.1553 - accuracy: 0.9494\n","Epoch 20/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.1463 - accuracy: 0.9551\n","Epoch 21/300\n","356/356 [==============================] - 0s 41us/sample - loss: 0.1379 - accuracy: 0.9579\n","Epoch 22/300\n","356/356 [==============================] - 0s 56us/sample - loss: 0.1304 - accuracy: 0.9607\n","Epoch 23/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.1245 - accuracy: 0.9663\n","Epoch 24/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.1191 - accuracy: 0.9635\n","Epoch 25/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.1165 - accuracy: 0.9635\n","Epoch 26/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.1088 - accuracy: 0.9663\n","Epoch 27/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.1036 - accuracy: 0.9663\n","Epoch 28/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0995 - accuracy: 0.9663\n","Epoch 29/300\n","356/356 [==============================] - 0s 39us/sample - loss: 0.0953 - accuracy: 0.9691\n","Epoch 30/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0901 - accuracy: 0.9747\n","Epoch 31/300\n","356/356 [==============================] - 0s 54us/sample - loss: 0.0871 - accuracy: 0.9803\n","Epoch 32/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0827 - accuracy: 0.9803\n","Epoch 33/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0792 - accuracy: 0.9775\n","Epoch 34/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0770 - accuracy: 0.9803\n","Epoch 35/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0730 - accuracy: 0.9803\n","Epoch 36/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0699 - accuracy: 0.9831\n","Epoch 37/300\n","356/356 [==============================] - 0s 68us/sample - loss: 0.0673 - accuracy: 0.9860\n","Epoch 38/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0645 - accuracy: 0.9860\n","Epoch 39/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0620 - accuracy: 0.9860\n","Epoch 40/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0596 - accuracy: 0.9831\n","Epoch 41/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0574 - accuracy: 0.9916\n","Epoch 42/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0553 - accuracy: 0.9888\n","Epoch 43/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0528 - accuracy: 0.9888\n","Epoch 44/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0501 - accuracy: 0.9888\n","Epoch 45/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0486 - accuracy: 0.9888\n","Epoch 46/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0466 - accuracy: 0.9916\n","Epoch 47/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0445 - accuracy: 0.9916\n","Epoch 48/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0430 - accuracy: 0.9888\n","Epoch 49/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0409 - accuracy: 0.9888\n","Epoch 50/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0400 - accuracy: 0.9916\n","Epoch 51/300\n","356/356 [==============================] - 0s 56us/sample - loss: 0.0389 - accuracy: 0.9916\n","Epoch 52/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0364 - accuracy: 0.9916\n","Epoch 53/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0351 - accuracy: 0.9916\n","Epoch 54/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0335 - accuracy: 0.9916\n","Epoch 55/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0322 - accuracy: 0.9916\n","Epoch 56/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0308 - accuracy: 0.9916\n","Epoch 57/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0298 - accuracy: 0.9972\n","Epoch 58/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0290 - accuracy: 0.9972\n","Epoch 59/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0273 - accuracy: 0.9972\n","Epoch 60/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0271 - accuracy: 0.9944\n","Epoch 61/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0257 - accuracy: 0.9944\n","Epoch 62/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0251 - accuracy: 0.9972\n","Epoch 63/300\n","356/356 [==============================] - 0s 54us/sample - loss: 0.0234 - accuracy: 0.9972\n","Epoch 64/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0226 - accuracy: 0.9944\n","Epoch 65/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0219 - accuracy: 0.9972\n","Epoch 66/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0207 - accuracy: 1.0000\n","Epoch 67/300\n","356/356 [==============================] - 0s 55us/sample - loss: 0.0198 - accuracy: 1.0000\n","Epoch 68/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0189 - accuracy: 1.0000\n","Epoch 69/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0183 - accuracy: 1.0000\n","Epoch 70/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0174 - accuracy: 1.0000\n","Epoch 71/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0169 - accuracy: 1.0000\n","Epoch 72/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0161 - accuracy: 1.0000\n","Epoch 73/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0156 - accuracy: 1.0000\n","Epoch 74/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0149 - accuracy: 1.0000\n","Epoch 75/300\n","356/356 [==============================] - 0s 41us/sample - loss: 0.0143 - accuracy: 1.0000\n","Epoch 76/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0138 - accuracy: 1.0000\n","Epoch 77/300\n","356/356 [==============================] - 0s 41us/sample - loss: 0.0132 - accuracy: 1.0000\n","Epoch 78/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0127 - accuracy: 1.0000\n","Epoch 79/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0123 - accuracy: 1.0000\n","Epoch 80/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0118 - accuracy: 1.0000\n","Epoch 81/300\n","356/356 [==============================] - 0s 53us/sample - loss: 0.0114 - accuracy: 1.0000\n","Epoch 82/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0110 - accuracy: 1.0000\n","Epoch 83/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0106 - accuracy: 1.0000\n","Epoch 84/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0104 - accuracy: 1.0000\n","Epoch 85/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0104 - accuracy: 1.0000\n","Epoch 86/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0096 - accuracy: 1.0000\n","Epoch 87/300\n","356/356 [==============================] - 0s 68us/sample - loss: 0.0093 - accuracy: 1.0000\n","Epoch 88/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0088 - accuracy: 1.0000\n","Epoch 89/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0085 - accuracy: 1.0000\n","Epoch 90/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0081 - accuracy: 1.0000\n","Epoch 91/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0077 - accuracy: 1.0000\n","Epoch 92/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0074 - accuracy: 1.0000\n","Epoch 93/300\n","356/356 [==============================] - 0s 54us/sample - loss: 0.0071 - accuracy: 1.0000\n","Epoch 94/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0069 - accuracy: 1.0000\n","Epoch 95/300\n","356/356 [==============================] - 0s 55us/sample - loss: 0.0066 - accuracy: 1.0000\n","Epoch 96/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0065 - accuracy: 1.0000\n","Epoch 97/300\n","356/356 [==============================] - 0s 56us/sample - loss: 0.0062 - accuracy: 1.0000\n","Epoch 98/300\n","356/356 [==============================] - 0s 53us/sample - loss: 0.0061 - accuracy: 1.0000\n","Epoch 99/300\n","356/356 [==============================] - 0s 55us/sample - loss: 0.0058 - accuracy: 1.0000\n","Epoch 100/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0056 - accuracy: 1.0000\n","Epoch 101/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0054 - accuracy: 1.0000\n","Epoch 102/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0053 - accuracy: 1.0000\n","Epoch 103/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0051 - accuracy: 1.0000\n","Epoch 104/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0050 - accuracy: 1.0000\n","Epoch 105/300\n","356/356 [==============================] - 0s 53us/sample - loss: 0.0048 - accuracy: 1.0000\n","Epoch 106/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0046 - accuracy: 1.0000\n","Epoch 107/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0045 - accuracy: 1.0000\n","Epoch 108/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0044 - accuracy: 1.0000\n","Epoch 109/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0043 - accuracy: 1.0000\n","Epoch 110/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0041 - accuracy: 1.0000\n","Epoch 111/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0040 - accuracy: 1.0000\n","Epoch 112/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0039 - accuracy: 1.0000\n","Epoch 113/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0038 - accuracy: 1.0000\n","Epoch 114/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0037 - accuracy: 1.0000\n","Epoch 115/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0036 - accuracy: 1.0000\n","Epoch 116/300\n","356/356 [==============================] - 0s 53us/sample - loss: 0.0035 - accuracy: 1.0000\n","Epoch 117/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0035 - accuracy: 1.0000\n","Epoch 118/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0033 - accuracy: 1.0000\n","Epoch 119/300\n","356/356 [==============================] - 0s 54us/sample - loss: 0.0033 - accuracy: 1.0000\n","Epoch 120/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0032 - accuracy: 1.0000\n","Epoch 121/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0031 - accuracy: 1.0000\n","Epoch 122/300\n","356/356 [==============================] - 0s 63us/sample - loss: 0.0030 - accuracy: 1.0000\n","Epoch 123/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0030 - accuracy: 1.0000\n","Epoch 124/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0029 - accuracy: 1.0000\n","Epoch 125/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0029 - accuracy: 1.0000\n","Epoch 126/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0028 - accuracy: 1.0000\n","Epoch 127/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0027 - accuracy: 1.0000\n","Epoch 128/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0026 - accuracy: 1.0000\n","Epoch 129/300\n","356/356 [==============================] - 0s 43us/sample - loss: 0.0026 - accuracy: 1.0000\n","Epoch 130/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0025 - accuracy: 1.0000\n","Epoch 131/300\n","356/356 [==============================] - 0s 51us/sample - loss: 0.0025 - accuracy: 1.0000\n","Epoch 132/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0024 - accuracy: 1.0000\n","Epoch 133/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0024 - accuracy: 1.0000\n","Epoch 134/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0023 - accuracy: 1.0000\n","Epoch 135/300\n","356/356 [==============================] - 0s 66us/sample - loss: 0.0023 - accuracy: 1.0000\n","Epoch 136/300\n","356/356 [==============================] - 0s 53us/sample - loss: 0.0022 - accuracy: 1.0000\n","Epoch 137/300\n","356/356 [==============================] - 0s 55us/sample - loss: 0.0022 - accuracy: 1.0000\n","Epoch 138/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0021 - accuracy: 1.0000\n","Epoch 139/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0021 - accuracy: 1.0000\n","Epoch 140/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0020 - accuracy: 1.0000\n","Epoch 141/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0020 - accuracy: 1.0000\n","Epoch 142/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0020 - accuracy: 1.0000\n","Epoch 143/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0019 - accuracy: 1.0000\n","Epoch 144/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0019 - accuracy: 1.0000\n","Epoch 145/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0019 - accuracy: 1.0000\n","Epoch 146/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0018 - accuracy: 1.0000\n","Epoch 147/300\n","356/356 [==============================] - 0s 58us/sample - loss: 0.0018 - accuracy: 1.0000\n","Epoch 148/300\n","356/356 [==============================] - 0s 42us/sample - loss: 0.0018 - accuracy: 1.0000\n","Epoch 149/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0017 - accuracy: 1.0000\n","Epoch 150/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0017 - accuracy: 1.0000\n","Epoch 151/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0016 - accuracy: 1.0000\n","Epoch 152/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0016 - accuracy: 1.0000\n","Epoch 153/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0016 - accuracy: 1.0000\n","Epoch 154/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0016 - accuracy: 1.0000\n","Epoch 155/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0015 - accuracy: 1.0000\n","Epoch 156/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0015 - accuracy: 1.0000\n","Epoch 157/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0015 - accuracy: 1.0000\n","Epoch 158/300\n","356/356 [==============================] - 0s 56us/sample - loss: 0.0015 - accuracy: 1.0000\n","Epoch 159/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0014 - accuracy: 1.0000\n","Epoch 160/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0014 - accuracy: 1.0000\n","Epoch 161/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0014 - accuracy: 1.0000\n","Epoch 162/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0014 - accuracy: 1.0000\n","Epoch 163/300\n","356/356 [==============================] - 0s 63us/sample - loss: 0.0013 - accuracy: 1.0000\n","Epoch 164/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0013 - accuracy: 1.0000\n","Epoch 165/300\n","356/356 [==============================] - 0s 44us/sample - loss: 0.0013 - accuracy: 1.0000\n","Epoch 166/300\n","356/356 [==============================] - 0s 57us/sample - loss: 0.0013 - accuracy: 1.0000\n","Epoch 167/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 168/300\n","356/356 [==============================] - 0s 50us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 169/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 170/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 171/300\n","356/356 [==============================] - 0s 46us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 172/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0012 - accuracy: 1.0000\n","Epoch 173/300\n","356/356 [==============================] - 0s 60us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 174/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 175/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 176/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 177/300\n","356/356 [==============================] - 0s 52us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 178/300\n","356/356 [==============================] - 0s 48us/sample - loss: 0.0011 - accuracy: 1.0000\n","Epoch 179/300\n","356/356 [==============================] - 0s 47us/sample - loss: 0.0010 - accuracy: 1.0000\n","Epoch 180/300\n","356/356 [==============================] - 0s 45us/sample - loss: 0.0010 - accuracy: 1.0000\n","Epoch 181/300\n","356/356 [==============================] - 0s 49us/sample - loss: 0.0010 - accuracy: 1.0000\n","Epoch 182/300\n","356/356 [==============================] - 0s 59us/sample - loss: 9.9712e-04 - accuracy: 1.0000\n","Epoch 183/300\n","356/356 [==============================] - 0s 49us/sample - loss: 9.8381e-04 - accuracy: 1.0000\n","Epoch 184/300\n","356/356 [==============================] - 0s 49us/sample - loss: 9.6830e-04 - accuracy: 1.0000\n","Epoch 185/300\n","356/356 [==============================] - 0s 44us/sample - loss: 9.5678e-04 - accuracy: 1.0000\n","Epoch 186/300\n","356/356 [==============================] - 0s 49us/sample - loss: 9.4164e-04 - accuracy: 1.0000\n","Epoch 187/300\n","356/356 [==============================] - 0s 49us/sample - loss: 9.2790e-04 - accuracy: 1.0000\n","Epoch 188/300\n","356/356 [==============================] - 0s 44us/sample - loss: 9.1708e-04 - accuracy: 1.0000\n","Epoch 189/300\n","356/356 [==============================] - 0s 45us/sample - loss: 9.0383e-04 - accuracy: 1.0000\n","Epoch 190/300\n","356/356 [==============================] - 0s 52us/sample - loss: 8.9342e-04 - accuracy: 1.0000\n","Epoch 191/300\n","356/356 [==============================] - 0s 51us/sample - loss: 8.7798e-04 - accuracy: 1.0000\n","Epoch 192/300\n","356/356 [==============================] - 0s 45us/sample - loss: 8.6781e-04 - accuracy: 1.0000\n","Epoch 193/300\n","356/356 [==============================] - 0s 44us/sample - loss: 8.5455e-04 - accuracy: 1.0000\n","Epoch 194/300\n","356/356 [==============================] - 0s 47us/sample - loss: 8.4421e-04 - accuracy: 1.0000\n","Epoch 195/300\n","356/356 [==============================] - 0s 44us/sample - loss: 8.3678e-04 - accuracy: 1.0000\n","Epoch 196/300\n","356/356 [==============================] - 0s 45us/sample - loss: 8.2222e-04 - accuracy: 1.0000\n","Epoch 197/300\n","356/356 [==============================] - 0s 42us/sample - loss: 8.2129e-04 - accuracy: 1.0000\n","Epoch 198/300\n","356/356 [==============================] - 0s 45us/sample - loss: 8.0054e-04 - accuracy: 1.0000\n","Epoch 199/300\n","356/356 [==============================] - 0s 52us/sample - loss: 7.9220e-04 - accuracy: 1.0000\n","Epoch 200/300\n","356/356 [==============================] - 0s 44us/sample - loss: 7.7994e-04 - accuracy: 1.0000\n","Epoch 201/300\n","356/356 [==============================] - 0s 47us/sample - loss: 7.7100e-04 - accuracy: 1.0000\n","Epoch 202/300\n","356/356 [==============================] - 0s 53us/sample - loss: 7.6012e-04 - accuracy: 1.0000\n","Epoch 203/300\n","356/356 [==============================] - 0s 50us/sample - loss: 7.5180e-04 - accuracy: 1.0000\n","Epoch 204/300\n","356/356 [==============================] - 0s 51us/sample - loss: 7.4155e-04 - accuracy: 1.0000\n","Epoch 205/300\n","356/356 [==============================] - 0s 49us/sample - loss: 7.3196e-04 - accuracy: 1.0000\n","Epoch 206/300\n","356/356 [==============================] - 0s 46us/sample - loss: 7.2373e-04 - accuracy: 1.0000\n","Epoch 207/300\n","356/356 [==============================] - 0s 50us/sample - loss: 7.1481e-04 - accuracy: 1.0000\n","Epoch 208/300\n","356/356 [==============================] - 0s 49us/sample - loss: 7.0736e-04 - accuracy: 1.0000\n","Epoch 209/300\n","356/356 [==============================] - 0s 46us/sample - loss: 6.9617e-04 - accuracy: 1.0000\n","Epoch 210/300\n","356/356 [==============================] - 0s 45us/sample - loss: 6.8668e-04 - accuracy: 1.0000\n","Epoch 211/300\n","356/356 [==============================] - 0s 49us/sample - loss: 6.7907e-04 - accuracy: 1.0000\n","Epoch 212/300\n","356/356 [==============================] - 0s 54us/sample - loss: 6.7195e-04 - accuracy: 1.0000\n","Epoch 213/300\n","356/356 [==============================] - 0s 53us/sample - loss: 6.6348e-04 - accuracy: 1.0000\n","Epoch 214/300\n","356/356 [==============================] - 0s 49us/sample - loss: 6.5500e-04 - accuracy: 1.0000\n","Epoch 215/300\n","356/356 [==============================] - 0s 53us/sample - loss: 6.4637e-04 - accuracy: 1.0000\n","Epoch 216/300\n","356/356 [==============================] - 0s 44us/sample - loss: 6.3883e-04 - accuracy: 1.0000\n","Epoch 217/300\n","356/356 [==============================] - 0s 44us/sample - loss: 6.3069e-04 - accuracy: 1.0000\n","Epoch 218/300\n","356/356 [==============================] - 0s 44us/sample - loss: 6.2363e-04 - accuracy: 1.0000\n","Epoch 219/300\n","356/356 [==============================] - 0s 52us/sample - loss: 6.1682e-04 - accuracy: 1.0000\n","Epoch 220/300\n","356/356 [==============================] - 0s 47us/sample - loss: 6.1004e-04 - accuracy: 1.0000\n","Epoch 221/300\n","356/356 [==============================] - 0s 45us/sample - loss: 6.0225e-04 - accuracy: 1.0000\n","Epoch 222/300\n","356/356 [==============================] - 0s 45us/sample - loss: 5.9533e-04 - accuracy: 1.0000\n","Epoch 223/300\n","356/356 [==============================] - 0s 45us/sample - loss: 5.8870e-04 - accuracy: 1.0000\n","Epoch 224/300\n","356/356 [==============================] - 0s 51us/sample - loss: 5.8038e-04 - accuracy: 1.0000\n","Epoch 225/300\n","356/356 [==============================] - 0s 47us/sample - loss: 5.7556e-04 - accuracy: 1.0000\n","Epoch 226/300\n","356/356 [==============================] - 0s 51us/sample - loss: 5.7012e-04 - accuracy: 1.0000\n","Epoch 227/300\n","356/356 [==============================] - 0s 54us/sample - loss: 5.6212e-04 - accuracy: 1.0000\n","Epoch 228/300\n","356/356 [==============================] - 0s 56us/sample - loss: 5.5641e-04 - accuracy: 1.0000\n","Epoch 229/300\n","356/356 [==============================] - 0s 45us/sample - loss: 5.4951e-04 - accuracy: 1.0000\n","Epoch 230/300\n","356/356 [==============================] - 0s 43us/sample - loss: 5.4400e-04 - accuracy: 1.0000\n","Epoch 231/300\n","356/356 [==============================] - 0s 44us/sample - loss: 5.3663e-04 - accuracy: 1.0000\n","Epoch 232/300\n","356/356 [==============================] - 0s 43us/sample - loss: 5.3106e-04 - accuracy: 1.0000\n","Epoch 233/300\n","356/356 [==============================] - 0s 51us/sample - loss: 5.2593e-04 - accuracy: 1.0000\n","Epoch 234/300\n","356/356 [==============================] - 0s 54us/sample - loss: 5.1961e-04 - accuracy: 1.0000\n","Epoch 235/300\n","356/356 [==============================] - 0s 44us/sample - loss: 5.1286e-04 - accuracy: 1.0000\n","Epoch 236/300\n","356/356 [==============================] - 0s 44us/sample - loss: 5.0841e-04 - accuracy: 1.0000\n","Epoch 237/300\n","356/356 [==============================] - 0s 46us/sample - loss: 5.0247e-04 - accuracy: 1.0000\n","Epoch 238/300\n","356/356 [==============================] - 0s 43us/sample - loss: 4.9748e-04 - accuracy: 1.0000\n","Epoch 239/300\n","356/356 [==============================] - 0s 49us/sample - loss: 4.9148e-04 - accuracy: 1.0000\n","Epoch 240/300\n","356/356 [==============================] - 0s 47us/sample - loss: 4.8610e-04 - accuracy: 1.0000\n","Epoch 241/300\n","356/356 [==============================] - 0s 45us/sample - loss: 4.8089e-04 - accuracy: 1.0000\n","Epoch 242/300\n","356/356 [==============================] - 0s 47us/sample - loss: 4.7577e-04 - accuracy: 1.0000\n","Epoch 243/300\n","356/356 [==============================] - 0s 45us/sample - loss: 4.7149e-04 - accuracy: 1.0000\n","Epoch 244/300\n","356/356 [==============================] - 0s 62us/sample - loss: 4.6653e-04 - accuracy: 1.0000\n","Epoch 245/300\n","356/356 [==============================] - 0s 51us/sample - loss: 4.6117e-04 - accuracy: 1.0000\n","Epoch 246/300\n","356/356 [==============================] - 0s 47us/sample - loss: 4.5819e-04 - accuracy: 1.0000\n","Epoch 247/300\n","356/356 [==============================] - 0s 57us/sample - loss: 4.5144e-04 - accuracy: 1.0000\n","Epoch 248/300\n","356/356 [==============================] - 0s 45us/sample - loss: 4.4824e-04 - accuracy: 1.0000\n","Epoch 249/300\n","356/356 [==============================] - 0s 44us/sample - loss: 4.4129e-04 - accuracy: 1.0000\n","Epoch 250/300\n","356/356 [==============================] - 0s 49us/sample - loss: 4.3811e-04 - accuracy: 1.0000\n","Epoch 251/300\n","356/356 [==============================] - 0s 44us/sample - loss: 4.3343e-04 - accuracy: 1.0000\n","Epoch 252/300\n","356/356 [==============================] - 0s 53us/sample - loss: 4.2910e-04 - accuracy: 1.0000\n","Epoch 253/300\n","356/356 [==============================] - 0s 46us/sample - loss: 4.2398e-04 - accuracy: 1.0000\n","Epoch 254/300\n","356/356 [==============================] - 0s 44us/sample - loss: 4.2016e-04 - accuracy: 1.0000\n","Epoch 255/300\n","356/356 [==============================] - 0s 45us/sample - loss: 4.1576e-04 - accuracy: 1.0000\n","Epoch 256/300\n","356/356 [==============================] - 0s 48us/sample - loss: 4.1296e-04 - accuracy: 1.0000\n","Epoch 257/300\n","356/356 [==============================] - 0s 46us/sample - loss: 4.0752e-04 - accuracy: 1.0000\n","Epoch 258/300\n","356/356 [==============================] - 0s 44us/sample - loss: 4.0531e-04 - accuracy: 1.0000\n","Epoch 259/300\n","356/356 [==============================] - 0s 52us/sample - loss: 3.9830e-04 - accuracy: 1.0000\n","Epoch 260/300\n","356/356 [==============================] - 0s 50us/sample - loss: 3.9483e-04 - accuracy: 1.0000\n","Epoch 261/300\n","356/356 [==============================] - 0s 49us/sample - loss: 3.9112e-04 - accuracy: 1.0000\n","Epoch 262/300\n","356/356 [==============================] - 0s 52us/sample - loss: 3.8715e-04 - accuracy: 1.0000\n","Epoch 263/300\n","356/356 [==============================] - 0s 53us/sample - loss: 3.8389e-04 - accuracy: 1.0000\n","Epoch 264/300\n","356/356 [==============================] - 0s 47us/sample - loss: 3.8213e-04 - accuracy: 1.0000\n","Epoch 265/300\n","356/356 [==============================] - 0s 47us/sample - loss: 3.7711e-04 - accuracy: 1.0000\n","Epoch 266/300\n","356/356 [==============================] - 0s 59us/sample - loss: 3.7252e-04 - accuracy: 1.0000\n","Epoch 267/300\n","356/356 [==============================] - 0s 42us/sample - loss: 3.6850e-04 - accuracy: 1.0000\n","Epoch 268/300\n","356/356 [==============================] - 0s 45us/sample - loss: 3.6557e-04 - accuracy: 1.0000\n","Epoch 269/300\n","356/356 [==============================] - 0s 45us/sample - loss: 3.6158e-04 - accuracy: 1.0000\n","Epoch 270/300\n","356/356 [==============================] - 0s 45us/sample - loss: 3.5742e-04 - accuracy: 1.0000\n","Epoch 271/300\n","356/356 [==============================] - 0s 44us/sample - loss: 3.5390e-04 - accuracy: 1.0000\n","Epoch 272/300\n","356/356 [==============================] - 0s 54us/sample - loss: 3.5032e-04 - accuracy: 1.0000\n","Epoch 273/300\n","356/356 [==============================] - 0s 42us/sample - loss: 3.4744e-04 - accuracy: 1.0000\n","Epoch 274/300\n","356/356 [==============================] - 0s 44us/sample - loss: 3.4480e-04 - accuracy: 1.0000\n","Epoch 275/300\n","356/356 [==============================] - 0s 48us/sample - loss: 3.3987e-04 - accuracy: 1.0000\n","Epoch 276/300\n","356/356 [==============================] - 0s 50us/sample - loss: 3.3500e-04 - accuracy: 1.0000\n","Epoch 277/300\n","356/356 [==============================] - 0s 46us/sample - loss: 3.3226e-04 - accuracy: 1.0000\n","Epoch 278/300\n","356/356 [==============================] - 0s 46us/sample - loss: 3.3032e-04 - accuracy: 1.0000\n","Epoch 279/300\n","356/356 [==============================] - 0s 42us/sample - loss: 3.2635e-04 - accuracy: 1.0000\n","Epoch 280/300\n","356/356 [==============================] - 0s 43us/sample - loss: 3.2044e-04 - accuracy: 1.0000\n","Epoch 281/300\n","356/356 [==============================] - 0s 48us/sample - loss: 3.1704e-04 - accuracy: 1.0000\n","Epoch 282/300\n","356/356 [==============================] - 0s 47us/sample - loss: 3.1220e-04 - accuracy: 1.0000\n","Epoch 283/300\n","356/356 [==============================] - 0s 68us/sample - loss: 3.0970e-04 - accuracy: 1.0000\n","Epoch 284/300\n","356/356 [==============================] - 0s 48us/sample - loss: 3.0529e-04 - accuracy: 1.0000\n","Epoch 285/300\n","356/356 [==============================] - 0s 45us/sample - loss: 3.0185e-04 - accuracy: 1.0000\n","Epoch 286/300\n","356/356 [==============================] - 0s 45us/sample - loss: 2.9866e-04 - accuracy: 1.0000\n","Epoch 287/300\n","356/356 [==============================] - 0s 43us/sample - loss: 2.9583e-04 - accuracy: 1.0000\n","Epoch 288/300\n","356/356 [==============================] - 0s 46us/sample - loss: 2.9202e-04 - accuracy: 1.0000\n","Epoch 289/300\n","356/356 [==============================] - 0s 45us/sample - loss: 2.8921e-04 - accuracy: 1.0000\n","Epoch 290/300\n","356/356 [==============================] - 0s 48us/sample - loss: 2.8588e-04 - accuracy: 1.0000\n","Epoch 291/300\n","356/356 [==============================] - 0s 47us/sample - loss: 2.8246e-04 - accuracy: 1.0000\n","Epoch 292/300\n","356/356 [==============================] - 0s 49us/sample - loss: 2.8106e-04 - accuracy: 1.0000\n","Epoch 293/300\n","356/356 [==============================] - 0s 51us/sample - loss: 2.7690e-04 - accuracy: 1.0000\n","Epoch 294/300\n","356/356 [==============================] - 0s 51us/sample - loss: 2.7444e-04 - accuracy: 1.0000\n","Epoch 295/300\n","356/356 [==============================] - 0s 52us/sample - loss: 2.7093e-04 - accuracy: 1.0000\n","Epoch 296/300\n","356/356 [==============================] - 0s 47us/sample - loss: 2.6936e-04 - accuracy: 1.0000\n","Epoch 297/300\n","356/356 [==============================] - 0s 48us/sample - loss: 2.6562e-04 - accuracy: 1.0000\n","Epoch 298/300\n","356/356 [==============================] - 0s 48us/sample - loss: 2.6301e-04 - accuracy: 1.0000\n","Epoch 299/300\n","356/356 [==============================] - 0s 45us/sample - loss: 2.6001e-04 - accuracy: 1.0000\n","Epoch 300/300\n","356/356 [==============================] - 0s 48us/sample - loss: 2.5770e-04 - accuracy: 1.0000\n"]}],"source":["# Fijamos la semilla para que no varie nuestro modelo de un entranamiento a otro\n","tf.random.set_seed(0)\n","optimizer = keras.optimizers.Adam(learning_rate=0.001)\n","es = keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=1000, restore_best_weights=True)\n","model = keras.Sequential([\n","\n","    layers.Dense(units= 10, activation='relu', input_shape=[64]),\n","    layers.Dense(units=10, activation='relu'),\n","    layers.Dense(units=10, activation='relu'),\n","\n","\n","\n","    \n","\n","\n","    layers.Dense(units=1,activation = 'sigmoid'),\n","])\n","model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'],experimental_run_tf_function=False)\n","\n","history = model.fit(\n","    x,y ,\n","    batch_size=60,\n","    epochs=300,\n","    callbacks = [es],\n","    verbose=1, # hide the output because we have so many epochs\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"elapsed":466,"status":"ok","timestamp":1663012029276,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"R-PqP4fnQJOO","outputId":"82960ee6-14e1-4ef1-afc8-36952731b659"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"execute_result","data":{"text/plain":["'bueno_digits_4_layers_1.00_accuracy.h5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":139}],"source":["accuracy = model.evaluate(x, y)[1]\n","layers_numbers = len(model.layers)\n","model_path = f'bueno_digits_{layers_numbers}_layers_{accuracy:.2f}_accuracy.h5'\n","model_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TN7rj9gNQal8"},"outputs":[],"source":["model.save(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GU7W7ZRDWBV4","executionInfo":{"status":"ok","timestamp":1663011043445,"user_tz":-120,"elapsed":959,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8275641b-de41-43d9-ba8c-91b151b08411"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["174"]},"metadata":{},"execution_count":131}],"source":["layer_outputs_digits = get_layers_output(model, x)\n","mask_digits_0 = [i==0 for i in y]\n","mask_digits_1 = [i==1 for i in y]\n","sum([1 for i in mask_digits_0 if i])"]},{"cell_type":"markdown","metadata":{"id":"t9OQoMylLOyM"},"source":["### Reporte de tipo k vecinos próximos"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3576,"status":"ok","timestamp":1663011756076,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"},"user_tz":-120},"id":"XLtzmdcYLM0i","outputId":"e9347b86-68c7-4974-c918-371f39091329"},"outputs":[{"output_type":"stream","name":"stdout","text":["Número de instancias: 165\n","número de vecinos: 3\n","Número de instancias: 152\n","número de vecinos: 3\n","------------CAPA 1------------\n","Número de instancias: 166\n","número de vecinos: 3\n","Número de instancias: 165\n","número de vecinos: 3\n","------------CAPA 2------------\n","Número de instancias: 172\n","número de vecinos: 3\n","Número de instancias: 157\n","número de vecinos: 3\n","------------CAPA 3------------\n","Número de instancias: 174\n","número de vecinos: 4\n","Número de instancias: 167\n","número de vecinos: 3\n","\\begin{tabular}{lrrrr}\n","\\toprule\n","{} &  c - Clase 8 &  d-Clase 8 &  c-Clase 1 &  d-Clase 1 \\\\\n","\\midrule\n","Entrada &     0.831490 &   3.187087 &   0.857910 &   2.835405 \\\\\n","Capa 1  &     0.729243 &   2.219888 &   0.957741 &   2.274444 \\\\\n","Capa 2  &     0.394193 &   2.221966 &   0.937739 &   2.476651 \\\\\n","Capa 3  &     0.099564 &   0.882331 &   0.907917 &   2.139596 \\\\\n","\\bottomrule\n","\\end{tabular}\n","\n"]}],"source":["print(do_report_table(x,layer_outputs_digits,mask_digits_0,mask_digits_1,3,0.8,'k').to_latex())"]},{"cell_type":"markdown","metadata":{"id":"Vc6PIdyfLTSk"},"source":["### Reporte de tipo radio "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-bqz4-7LWTKu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662903734961,"user_tz":-120,"elapsed":37828,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"outputId":"777e37cf-8d61-4fe1-a52f-ee5c990f7b1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["------------ Input ------------\n","Número de instancias: 122\n","radio: 22.280000000000683\n","Variedad_0: c, d (0.9181403213955875, 1.6687281040205002)\n","Número de instancias: 145\n","radio: 19.420000000000236\n","Variedad_1: c, d (0.9181640868189949, 2.0030729092805797)\n","------------CAPA 1------------\n","Número de instancias: 122\n","radio: 5.199999999999934\n","Variedad_0: c, d: (0.9726883553609743, 0.8748769643399033)\n","Número de instancias: 137\n","radio: 6.529999999999905\n","Variedad_1: c, d (0.834442408324243, 1.7684780607397772)\n","------------CAPA 2------------\n","Número de instancias: 127\n","radio: 1.8600000000000014\n","Variedad_0: c, d: (0.9758343500562816, 0.7972312792610193)\n","Número de instancias: 130\n","radio: 1.9800000000000015\n","Variedad_1: c, d (0.9955539378880658, 1.0161563719404019)\n","------------CAPA 3------------\n","Número de instancias: 122\n","radio: 0.4400000000000002\n","Variedad_0: c, d: (1.0533673058568735, 5.131798104807698)\n","Número de instancias: 147\n","radio: 1.1100000000000008\n","Variedad_1: c, d (0.933142151230111, 1.2034969325831149)\n","------------CAPA 4------------\n","Número de instancias: 173\n","radio: 0.01\n","Variedad_0: c, d: (0.3271406062184807, 3.7188338359655906)\n","radio: 0.01\n","Variedad_1: c, d (6.071278321560883e-05, inf)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]}],"source":["do_report(x,layer_outputs_digits,mask_digits_0,mask_digits_1,0.7,'r')\n"]},{"cell_type":"code","source":[],"metadata":{"id":"LLNq-i6yzcmA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reporte radio en formato tabla\n"],"metadata":{"id":"RACjr-gpvbLP"}},{"cell_type":"code","source":["do_report_table(x,layer_outputs_digits,mask_digits_0,mask_digits_1,ratio_min = 1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":510},"id":"y03aRueEvaTM","executionInfo":{"status":"ok","timestamp":1662903575143,"user_tz":-120,"elapsed":71041,"user":{"displayName":"David Zumaquero Mairena","userId":"16350040826034481586"}},"outputId":"c6b7c2b5-267a-4835-8994-1516f2e21641"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["radio: 32.12000000000218\n","radio: 30.84000000000202\n","------------CAPA 1------------\n","radio: 15.429999999999715\n","radio: 11.299999999999804\n","------------CAPA 2------------\n","radio: 7.779999999999879\n","radio: 4.8299999999999415\n","------------CAPA 3------------\n","radio: 5.279999999999932\n","radio: 2.7799999999999847\n","------------CAPA 4------------\n","radio: 0.35000000000000014\n","radio: 0.01\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in true_divide\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["         c - Clase 1     d-Clase 1  c-Clase 0  d-Clase 0\n","Entrada     0.090880  3.909119e-01   0.154802   0.527509\n","Capa 1      0.007983  1.817751e-02   0.075225   0.273454\n","Capa 2      0.008271  8.403997e-03   0.071712   0.099952\n","Capa 3      0.000083  6.236643e-04   0.065141   0.075755\n","Capa 4      0.000066  1.518707e-08   0.000061        inf"],"text/html":["\n","  <div id=\"df-d026fc5b-acf4-4eee-bf53-f1b49698a9c9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>c - Clase 1</th>\n","      <th>d-Clase 1</th>\n","      <th>c-Clase 0</th>\n","      <th>d-Clase 0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Entrada</th>\n","      <td>0.090880</td>\n","      <td>3.909119e-01</td>\n","      <td>0.154802</td>\n","      <td>0.527509</td>\n","    </tr>\n","    <tr>\n","      <th>Capa 1</th>\n","      <td>0.007983</td>\n","      <td>1.817751e-02</td>\n","      <td>0.075225</td>\n","      <td>0.273454</td>\n","    </tr>\n","    <tr>\n","      <th>Capa 2</th>\n","      <td>0.008271</td>\n","      <td>8.403997e-03</td>\n","      <td>0.071712</td>\n","      <td>0.099952</td>\n","    </tr>\n","    <tr>\n","      <th>Capa 3</th>\n","      <td>0.000083</td>\n","      <td>6.236643e-04</td>\n","      <td>0.065141</td>\n","      <td>0.075755</td>\n","    </tr>\n","    <tr>\n","      <th>Capa 4</th>\n","      <td>0.000066</td>\n","      <td>1.518707e-08</td>\n","      <td>0.000061</td>\n","      <td>inf</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d026fc5b-acf4-4eee-bf53-f1b49698a9c9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d026fc5b-acf4-4eee-bf53-f1b49698a9c9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d026fc5b-acf4-4eee-bf53-f1b49698a9c9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":[],"metadata":{"id":"NNEfA4sYx0iO"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["Y5VArjLIB2gQ","18Y1p2kdGGf0","NYEztlrIGLrw","XZlJ1pNlQF9m","t9OQoMylLOyM"],"provenance":[],"mount_file_id":"1YHvv7FM1dfDJQ7QvmN9AWJTYtLzeVO0q","authorship_tag":"ABX9TyPyHXBG0HdM/FG/SF8DOoYp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}